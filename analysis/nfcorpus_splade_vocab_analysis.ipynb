{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c740b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import AutoTokenizer, BasicTokenizer, AutoModelForMaskedLM\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from tqdm import tqdm_notebook\n",
    "import pytrec_eval\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from splade_vocab.models  import Splade, BEIRSpladeModel, BEIRSpladeModelIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff01cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2700e04d7d4affaf23ec962bba0e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"/home/gaia_data/iida.h/BEIR/datasets/nfcorpus\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1376c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_result(model_path):\n",
    "    model = Splade(model_path)\n",
    "    model.eval()\n",
    "    tokenizer = model.tokenizer\n",
    "    beir_splade = BEIRSpladeModel(model, tokenizer)\n",
    "    dres = DRES(beir_splade)\n",
    "    retriever = EvaluateRetrieval(dres, score_function=\"dot\")\n",
    "    results = retriever.retrieve(corpus, queries)\n",
    "    del retriever\n",
    "    del dres\n",
    "    del model\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cfcc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pathes = {\"mlm-splade-71694\": \"/home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\",\n",
    "               \"mlm-splade-30522\": \"/home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\",\n",
    "                \"splade-71694\": \"/home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\",\n",
    "               \"splade\": \"/home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_40-2022-05-01_12-37-20\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef593e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tks = {\"splade-71694\": AutoTokenizer.from_pretrained(os.path.join(model_pathes[\"mlm-splade-71694\"], \"0_MLMTransformer\")),\n",
    "       \"splade\": AutoTokenizer.from_pretrained(os.path.join(model_pathes[\"splade\"], \"0_MLMTransformer\")),\n",
    "      \"space\": BasicTokenizer()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888036a",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c8875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_move(ini_model, splade_model):\n",
    "    mlm_head_vec = ini_model.cls.predictions.decoder.weight\n",
    "    mlm_sphead_vec = splade_model.transformer.cls.predictions.decoder.weight\n",
    "    mlm_head_vec_norm = mlm_head_vec / torch.unsqueeze(torch.norm(mlm_head_vec, dim=1), 1)\n",
    "    mlm_sphead_vec_norm = mlm_sphead_vec / torch.unsqueeze(torch.norm(mlm_sphead_vec, dim=1), 1)\n",
    "    l2 = torch.norm(mlm_head_vec - mlm_sphead_vec, dim=1)\n",
    "    l2_org = torch.mean(l2[:30522])\n",
    "    l2_add = torch.mean(l2[30522:])\n",
    "    print(f\"l2_org: {l2_org}, l2_add: {l2_add}\")\n",
    "    cos_sim = torch.sum(mlm_head_vec_norm * mlm_sphead_vec_norm, dim=1)\n",
    "    cos_sim_org = torch.mean(cos_sim[:30522])\n",
    "    cos_sim_add = torch.mean(cos_sim[30522:])\n",
    "    print(f\"cos_sim_org: {cos_sim_org}, cos_sim_add: {cos_sim_add}\")\n",
    "    topk_sim, topk_ids = torch.topk(-cos_sim, 50)\n",
    "    print(-topk_sim)\n",
    "    print(topk_ids)\n",
    "    print(splade_model.tokenizer.decode(topk_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5c21c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n",
      "l2_org: 0.15013934671878815, l2_add: 0.1105366200208664\n",
      "cos_sim_org: 0.9936464428901672, cos_sim_add: 0.9946423172950745\n",
      "tensor([0.7846, 0.8510, 0.8895, 0.8917, 0.8968, 0.9234, 0.9273, 0.9407, 0.9428,\n",
      "        0.9429, 0.9431, 0.9433, 0.9433, 0.9437, 0.9471, 0.9477, 0.9485, 0.9498,\n",
      "        0.9520, 0.9539, 0.9542, 0.9542, 0.9550, 0.9551, 0.9552, 0.9552, 0.9552,\n",
      "        0.9564, 0.9567, 0.9574, 0.9574, 0.9578, 0.9584, 0.9593, 0.9593, 0.9596,\n",
      "        0.9597, 0.9599, 0.9600, 0.9603, 0.9603, 0.9613, 0.9615, 0.9616, 0.9618,\n",
      "        0.9619, 0.9625, 0.9626, 0.9629, 0.9633], grad_fn=<NegBackward0>)\n",
      "tensor([ 1010,  1996,  1012,  1011,  1998,  1999,  1000,  2008,  1037,  2030,\n",
      "         2006,  2028,  1997,  2036,  2035,  1006,  2007,  2001,  2000,  1007,\n",
      "         2062,  2009,  2119,  1025,  2048,  2034,  2069,  2004, 38445,  2018,\n",
      "         2051,  2025,  2089,  2020, 43360,  2005,  2021,  2101,  2023,  2152,\n",
      "         2195, 36846, 55693,  2187,  1005,  2070,  2047, 38964,  2011,  2491])\n",
      ", the. - and in \" that a or on one of also all ( with was to ) more it both ; two first only as ath had time not may were ita for but later this high several bak redirected left'some new preh by control\n"
     ]
    }
   ],
   "source": [
    "mlm_splade_71694 = Splade(model_pathes[\"mlm-splade-71694\"])\n",
    "mlm_71694 = AutoModelForMaskedLM.from_pretrained(\"/home/gaia_data/iida.h/BEIR/model/pubmed_abst//bert-base-uncased/mlm_model/raw/remove/71694/\")\n",
    "embed_move(mlm_71694, mlm_splade_71694)\n",
    "del mlm_splade_71694\n",
    "del mlm_71694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5381775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n",
      "l2_org: 0.20315341651439667, l2_add: nan\n",
      "cos_sim_org: 0.9896920323371887, cos_sim_add: nan\n",
      "tensor([0.8513, 0.8847, 0.9096, 0.9107, 0.9143, 0.9148, 0.9336, 0.9387, 0.9422,\n",
      "        0.9423, 0.9447, 0.9456, 0.9487, 0.9493, 0.9496, 0.9496, 0.9500, 0.9504,\n",
      "        0.9512, 0.9524, 0.9533, 0.9534, 0.9535, 0.9542, 0.9548, 0.9552, 0.9554,\n",
      "        0.9555, 0.9556, 0.9557, 0.9560, 0.9562, 0.9565, 0.9566, 0.9567, 0.9572,\n",
      "        0.9572, 0.9573, 0.9574, 0.9575, 0.9578, 0.9578, 0.9579, 0.9582, 0.9582,\n",
      "        0.9587, 0.9588, 0.9589, 0.9591, 0.9591], grad_fn=<NegBackward0>)\n",
      "tensor([1010, 1996, 1011, 1998, 1000, 1012, 1999, 2001, 2018, 2008, 2249, 1037,\n",
      "        1025, 2009, 2441, 2262, 2004, 2036, 2035, 2015, 2030, 2006, 2111, 2002,\n",
      "        2012, 4725, 2143, 2263, 2048, 2117, 2268, 2513, 2384, 1045, 1997,  102,\n",
      "        2007, 4871, 2297, 2536, 2028, 2286, 2000, 2294, 2333, 2119, 2456, 2027,\n",
      "        2418, 2872])\n",
      ", the - and \". in was had that 2011 a ; it opened 2012 as also alls or on people he at methods film 2008 two second 2009 returned 2005 i of [SEP] with images 2014 various one 2013 to 2006 moved both 2000 they 2017 placed\n"
     ]
    }
   ],
   "source": [
    "mlm_splade = Splade(model_pathes[\"mlm-splade-30522\"])\n",
    "mlm_bert = AutoModelForMaskedLM.from_pretrained(\"/home/gaia_data/iida.h/BEIR/model/pubmed_abst//bert-base-uncased/mlm_model/raw/remove/30522/\")\n",
    "embed_move(mlm_bert, mlm_splade)\n",
    "del mlm_bert\n",
    "del mlm_splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe4fee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_24-2022-04-07_21-45-37/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_org: 0.20133037865161896, l2_add: nan\n",
      "cos_sim_org: 0.9893619418144226, cos_sim_add: nan\n",
      "tensor([0.9144, 0.9246, 0.9302, 0.9306, 0.9345, 0.9430, 0.9469, 0.9476, 0.9480,\n",
      "        0.9484, 0.9489, 0.9494, 0.9499, 0.9503, 0.9512, 0.9522, 0.9529, 0.9532,\n",
      "        0.9543, 0.9543, 0.9544, 0.9546, 0.9549, 0.9549, 0.9551, 0.9552, 0.9552,\n",
      "        0.9555, 0.9556, 0.9556, 0.9560, 0.9561, 0.9562, 0.9562, 0.9562, 0.9565,\n",
      "        0.9565, 0.9566, 0.9568, 0.9570, 0.9572, 0.9576, 0.9577, 0.9577, 0.9578,\n",
      "        0.9579, 0.9581, 0.9582, 0.9582, 0.9582], grad_fn=<NegBackward0>)\n",
      "tensor([1996, 1010, 1000, 1998, 1012, 2249, 2001, 1025, 2002, 1011, 2008, 1999,\n",
      "        2004, 2195, 2012, 2111, 2268, 2048, 2418, 3150, 2441, 2333, 2262, 4350,\n",
      "        2456, 2053, 2164, 2036, 2526, 2329, 2006, 2371, 2225, 2021, 2030, 2009,\n",
      "        2013, 2294, 3440, 2251, 2286, 2117, 2034,  999, 2061, 2081, 2506, 2238,\n",
      "        2760, 2146])\n",
      "the, \" and. 2011 was ; he - that in as several at people 2009 two 2017 1980 opened moved 2012 situated 2000 no including also 2002 british on felt west but or it from 2006 1969 july 2013 second first! so made continued june 2018 long\n"
     ]
    }
   ],
   "source": [
    "splade = Splade(model_pathes[\"splade\"])\n",
    "bert = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "embed_move(bert, splade)\n",
    "del bert\n",
    "del splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9837c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad512f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398960f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84a426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad56607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810c31e616c44113b1932d02bf7f8094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4c92dc9d6c4056a9dc1a16c65308b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500e08f7a5fd43928df44b5db0196d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf35697c7c444f8ab06f3ce2de5f0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7171fb5862994bc2ba987489ed0e2920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133317475bf244c88b0c629a11ca467f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_40-2022-05-01_12-37-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75574bcbd6384f89a3b48df92eff489e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0101bc9fdd46d3a5a4b7c182cb2ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = {}\n",
    "for k, model_path in model_pathes.items():\n",
    "    results = search_result(model_path)\n",
    "    all_results[k] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6c3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'ndcg_cut_10'})\n",
    "all_ndcg = {}\n",
    "all_ave_ndcg = {}\n",
    "for k, result in all_results.items():\n",
    "    ndcg = evaluator.evaluate(result)\n",
    "    all_ndcg[k] = ndcg\n",
    "    all_ave_ndcg[k] = np.mean([val[\"ndcg_cut_10\"] for val in ndcg.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a23d44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlm-splade-71694': 0.34793522628074985,\n",
       " 'mlm-splade-30522': 0.33529012462911234,\n",
       " 'splade-71694': 0.34578516560691475,\n",
       " 'splade': 0.3360477401299443}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ave_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "328ef1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlm-splade-71694</th>\n",
       "      <th>mlm-splade-30522</th>\n",
       "      <th>splade-71694</th>\n",
       "      <th>splade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.758692</td>\n",
       "      <td>0.772313</td>\n",
       "      <td>0.772313</td>\n",
       "      <td>0.780089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094567</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>0.087076</td>\n",
       "      <td>0.154232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327307</td>\n",
       "      <td>0.394345</td>\n",
       "      <td>0.510254</td>\n",
       "      <td>0.518469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340985</td>\n",
       "      <td>0.439179</td>\n",
       "      <td>0.454814</td>\n",
       "      <td>0.393657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.246906</td>\n",
       "      <td>0.118584</td>\n",
       "      <td>0.244641</td>\n",
       "      <td>0.167613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mlm-splade-71694  mlm-splade-30522  splade-71694    splade\n",
       "0          0.758692          0.772313      0.772313  0.780089\n",
       "1          0.094567          0.105280      0.087076  0.154232\n",
       "2          0.327307          0.394345      0.510254  0.518469\n",
       "3          0.340985          0.439179      0.454814  0.393657\n",
       "4          0.246906          0.118584      0.244641  0.167613"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ndcg = {}\n",
    "model_names = [\"mlm-splade-71694\", \"mlm-splade-30522\", \"splade-71694\", \"splade\"]\n",
    "for k in model_names:\n",
    "    target = all_ndcg[k]\n",
    "    df_all_ndcg[k] = [val['ndcg_cut_10'] for val in target.values()]\n",
    "    \n",
    "df_all_ndcg = pd.DataFrame(df_all_ndcg)\n",
    "df_all_ndcg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f17ff612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlm-splade-71694</th>\n",
       "      <th>mlm-splade-30522</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021397</td>\n",
       "      <td>-0.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059665</td>\n",
       "      <td>-0.048952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.191163</td>\n",
       "      <td>-0.124124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052672</td>\n",
       "      <td>0.045522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079293</td>\n",
       "      <td>-0.049029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.051163</td>\n",
       "      <td>-0.153817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mlm-splade-71694  mlm-splade-30522\n",
       "0           -0.021397         -0.007776\n",
       "1           -0.059665         -0.048952\n",
       "2           -0.191163         -0.124124\n",
       "3           -0.052672          0.045522\n",
       "4            0.079293         -0.049029\n",
       "..                ...               ...\n",
       "318         -0.051163         -0.153817\n",
       "319          0.000000          0.000000\n",
       "320          0.000000          0.046816\n",
       "321          0.000000          0.081229\n",
       "322          0.000000          0.000000\n",
       "\n",
       "[323 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_from_splade = {}\n",
    "diff_model_names = [\"mlm-splade-71694\", \"mlm-splade-30522\"]\n",
    "q_index = list(queries.keys())\n",
    "for k in diff_model_names:\n",
    "    target = all_ndcg[k]\n",
    "    base = all_ndcg[\"splade\"]\n",
    "    diff_from_splade[k] = [val1[\"ndcg_cut_10\"] - val2[\"ndcg_cut_10\"] for val1, val2 in zip(target.values(), base.values())]\n",
    "    \n",
    "df_diff_from_splade = pd.DataFrame(diff_from_splade)\n",
    "df_diff_from_splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06340f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlm-splade-71694</th>\n",
       "      <th>splade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013621</td>\n",
       "      <td>0.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010713</td>\n",
       "      <td>0.048952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.067039</td>\n",
       "      <td>0.124124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.098194</td>\n",
       "      <td>-0.045522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128322</td>\n",
       "      <td>0.049029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.102654</td>\n",
       "      <td>0.153817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-0.046816</td>\n",
       "      <td>-0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.081229</td>\n",
       "      <td>-0.081229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mlm-splade-71694    splade\n",
       "0           -0.013621  0.007776\n",
       "1           -0.010713  0.048952\n",
       "2           -0.067039  0.124124\n",
       "3           -0.098194 -0.045522\n",
       "4            0.128322  0.049029\n",
       "..                ...       ...\n",
       "318          0.102654  0.153817\n",
       "319          0.000000  0.000000\n",
       "320         -0.046816 -0.046816\n",
       "321         -0.081229 -0.081229\n",
       "322          0.000000  0.000000\n",
       "\n",
       "[323 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_from_mlm_splade = {}\n",
    "diff_model_names = [\"mlm-splade-71694\", \"splade\"]\n",
    "q_index = list(queries.keys())\n",
    "for k in diff_model_names:\n",
    "    target = all_ndcg[k]\n",
    "    base = all_ndcg[\"mlm-splade-30522\"]\n",
    "    diff_from_mlm_splade[k] = [val1[\"ndcg_cut_10\"] - val2[\"ndcg_cut_10\"] for val1, val2 in zip(target.values(), base.values())]\n",
    "    \n",
    "df_diff_from_mlm_splade = pd.DataFrame(diff_from_mlm_splade)\n",
    "df_diff_from_mlm_splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f4830a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids_adalm_splade_better = df_diff_from_splade[(df_diff_from_splade[\"mlm-splade-71694\"] > 0.0)].index\n",
    "qids_adalm_splade_better = [q_index[i] for i in qids_adalm_splade_better]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e2d7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids_adalm_splade_worse = df_diff_from_splade[df_diff_from_splade[\"mlm-splade-71694\"] < 0.0].index\n",
    "qids_adalm_splade_worse = [q_index[i] for i in qids_adalm_splade_worse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f643cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_em_w_space_tk(model_name, qids, all_results):\n",
    "    def encode_doc(model, e_query, text, t_query, t_query_space):\n",
    "        t_text = model.tokenizer(text, max_length=512, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            t_text = {k: v.to(device) for k, v in t_text.items()}\n",
    "            e_text = model.encode(**t_text)\n",
    "            match_scores = e_query * e_text\n",
    "            score, ids = torch.topk(match_scores, k=20)\n",
    "            ids = ids[0][score[0] > 0.1]\n",
    "            score = score[0][score[0] > 0.1]\n",
    "            tids = model.tokenizer.decode(ids)\n",
    "        t_tids = tids.split()\n",
    "        match_type = {\"em\": [], \"not-em\": [], \"space-tk\": []}\n",
    "        not_em = []\n",
    "        for t in t_tids:\n",
    "            if t in t_query:\n",
    "                match_type[\"em\"].append(t)\n",
    "            else:\n",
    "                match_type[\"not-em\"].append(t)\n",
    "         \n",
    "            if t in t_query_space:\n",
    "                match_type[\"space-tk\"].append(t)\n",
    "                \n",
    "        return match_type\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    model_path = model_pathes[model_name]\n",
    "    model = Splade(model_path)\n",
    "    model.to(device)\n",
    "    space_tk = BasicTokenizer()\n",
    "    \n",
    "    match_token_splade_nums = []\n",
    "    expand_token_splade_nums = []\n",
    "    match_token_tk_nums = []\n",
    "        \n",
    "    for qid in qids:\n",
    "        query = queries[qid]\n",
    "        top_10_doc = sorted(all_results[model_name][qid].items(), key=lambda x: -x[1])[:10]\n",
    "        t_query_id = model.tokenizer(query, max_length=512, return_tensors=\"pt\")\n",
    "        t_query_id = {k: v.to(device) for k, v in t_query_id.items()}\n",
    "        t_query = model.tokenizer.tokenize(query)\n",
    "        t_query_space = space_tk.tokenize(query)\n",
    "        with torch.no_grad():    \n",
    "            e_query = model.encode(**t_query_id)\n",
    "\n",
    "        top_qrels = []\n",
    "        try:\n",
    "            q_qrels = qrels[qid]\n",
    "        except:\n",
    "            continue\n",
    "        for i, (cid, qrel) in enumerate(q_qrels.items()):            \n",
    "            if qrel > 0:\n",
    "                text = corpus[cid][\"title\"] + \" \" + corpus[cid][\"text\"]\n",
    "                t_text = model.tokenizer.tokenize(text)\n",
    "                match_token_tk_nums.append(len([t for t in t_query if t in t_text]))\n",
    "                match_type = encode_doc(model, e_query, text, t_query, t_query_space)\n",
    "                match_token_splade_nums.append(len(match_type[\"em\"]))\n",
    "                expand_token_splade_nums.append(len(match_type[\"not-em\"]))\n",
    "        \n",
    "\n",
    "    return match_token_tk_nums, match_token_splade_nums, expand_token_splade_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae1c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-71694, em_tk: 0.7366015787287079, em_splade: 0.5675114250103864, expand: 3.2370170336518487\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-30522, em_tk: 1.002492729538845, em_splade: 0.5446614042376402, expand: 1.8635230577482342\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade-71694, em_tk: 0.7366015787287079, em_splade: 0.5191109264644787, expand: 2.8739094308267554\n",
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_24-2022-04-07_21-45-37/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade, em_tk: 1.002492729538845, em_splade: 0.4948068134607395, expand: 2.4941836310760284\n"
     ]
    }
   ],
   "source": [
    "observe_model = [\"mlm-splade-71694\", \"mlm-splade-30522\", \"splade-71694\", \"splade\"]\n",
    "# observe_model = [\"mlm-splade-62783\", \"splade\"]\n",
    "for model_name in observe_model:\n",
    "    match_token_tk_nums, match_token_splade_nums, expand_token_splade_nums = count_em_w_space_tk(model_name, qids_adalm_splade_better, all_results)\n",
    "    print(f\"{model_name}, em_tk: {np.mean(match_token_tk_nums)}, em_splade: {np.mean(match_token_splade_nums)}, expand: {np.mean(expand_token_splade_nums)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ed03252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-71694, em_tk: 0.9676992321948636, em_splade: 0.740799576383373, expand: 3.0254169976171563\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-30522, em_tk: 1.2306063012973258, em_splade: 0.6904951019327509, expand: 1.6025946518400846\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade-71694, em_tk: 0.9676992321948636, em_splade: 0.6952607889859677, expand: 2.9780248874768334\n",
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_24-2022-04-07_21-45-37/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade, em_tk: 1.2306063012973258, em_splade: 0.691289383108287, expand: 2.2975906804342072\n"
     ]
    }
   ],
   "source": [
    "observe_model = [\"mlm-splade-71694\", \"mlm-splade-30522\", \"splade-71694\", \"splade\"]\n",
    "# observe_model = [\"mlm-splade-62783\", \"splade\"]\n",
    "for model_name in observe_model:\n",
    "    match_token_tk_nums, match_token_splade_nums, expand_token_splade_nums = count_em_w_space_tk(model_name, qids_adalm_splade_worse, all_results)\n",
    "    print(f\"{model_name}, em_tk: {np.mean(match_token_tk_nums)}, em_splade: {np.mean(match_token_splade_nums)}, expand: {np.mean(expand_token_splade_nums)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4782df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-71694, em_tk: 0.7456623966272093, em_splade: 0.5842386898005513, expand: 3.1595589427598507\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-30522, em_tk: 0.9825685098102805, em_splade: 0.5404572725798605, expand: 1.6108318469271932\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade-71694, em_tk: 0.7456623966272093, em_splade: 0.536322360953462, expand: 2.9527322847413653\n",
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_24-2022-04-07_21-45-37/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade, em_tk: 0.9825685098102805, em_splade: 0.5124858115777525, expand: 2.3431165882925247\n"
     ]
    }
   ],
   "source": [
    "observe_model = [\"mlm-splade-71694\", \"mlm-splade-30522\", \"splade-71694\", \"splade\"]\n",
    "# observe_model = [\"mlm-splade-62783\", \"splade\"]\n",
    "for model_name in observe_model:\n",
    "    match_token_tk_nums, match_token_splade_nums, expand_token_splade_nums = count_em_w_space_tk(model_name, q_index, all_results)\n",
    "    print(f\"{model_name}, em_tk: {np.mean(match_token_tk_nums)}, em_splade: {np.mean(match_token_splade_nums)}, expand: {np.mean(expand_token_splade_nums)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604aa8c",
   "metadata": {},
   "source": [
    "# Check Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a1982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    }
   ],
   "source": [
    "model = Splade(model_pathes[\"mlm-splade-71694\"])\n",
    "model = model.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bde3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330048/2062905229.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for cid in tqdm_notebook(corpus):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733d463d27924d33b9582133ec12d9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  291.7742912193779\n",
      "var:  4079.336889292566\n",
      "std:  63.86968677935227\n"
     ]
    }
   ],
   "source": [
    "all_doc_len = []\n",
    "for cid in tqdm_notebook(corpus):\n",
    "    text = corpus[cid][\"title\"] + \" \" + corpus[cid][\"text\"]\n",
    "    t_text_id = model.tokenizer(text, max_length=512, return_tensors=\"pt\")\n",
    "    for k in t_text_id:\n",
    "        t_text_id[k] = t_text_id[k].to(torch.device(\"cuda\"))\n",
    "    with torch.no_grad():\n",
    "        e_text = model.encode(**t_text_id)\n",
    "    e_doc_len = torch.sum(e_text > 0)\n",
    "    all_doc_len.append(e_doc_len.cpu().numpy())\n",
    "    \n",
    "print(\"mean: \", np.mean(all_doc_len))\n",
    "print(\"var: \", np.var(all_doc_len))\n",
    "print(\"std: \", np.std(all_doc_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c497473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330048/1443639527.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for cid in tqdm_notebook(corpus):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2219f049e34fbe97a251775ae8ffb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  175.47068538398017\n",
      "var:  4273.928744286648\n",
      "std:  65.37529154265125\n"
     ]
    }
   ],
   "source": [
    "analyzer = Analyzer(get_lucene_analyzer())\n",
    "all_doc_len = []\n",
    "vocab = set()\n",
    "for cid in tqdm_notebook(corpus):\n",
    "    text = corpus[cid][\"title\"] + \" \" + corpus[cid][\"text\"]\n",
    "    t_text = analyzer.analyze(text)\n",
    "    all_doc_len.append(len(t_text))\n",
    "    vocab |= set(t_text)\n",
    "    \n",
    "print(\"mean: \", np.mean(all_doc_len))\n",
    "print(\"var: \", np.var(all_doc_len))\n",
    "print(\"std: \", np.std(all_doc_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6140eef",
   "metadata": {},
   "source": [
    "# domain specificc words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83609806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_w_space_tk(model_name, qids, all_results):\n",
    "    def encode_doc(model, e_query, text, t_query, t_query_space):\n",
    "        t_text_id = model.tokenizer(text, max_length=512, return_tensors=\"pt\")\n",
    "        t_text = model.tokenizer.tokenize(text)\n",
    "        with torch.no_grad():\n",
    "            e_text = model.encode(**t_text_id)\n",
    "            match_scores = e_query * e_text\n",
    "            score, ids = torch.topk(match_scores, k=20)\n",
    "            ids = ids[0][score[0] > 0.0]\n",
    "            score = score[0][score[0] > 0.0]\n",
    "            tids = model.tokenizer.decode(ids)\n",
    "        t_tids = tids.split()\n",
    "        match_type = {\"em\": [], \"not-em\": [], \"space-tk\": []}\n",
    "        not_em = []\n",
    "        for t in t_tids:\n",
    "            if t in t_text:\n",
    "                match_type[\"em\"].append(t)\n",
    "            else:\n",
    "                match_type[\"not-em\"].append(t)\n",
    "         \n",
    "            if t in t_query_space:\n",
    "                match_type[\"space-tk\"].append(t)\n",
    "                \n",
    "        return match_type\n",
    "    \n",
    "    model_path = model_pathes[model_name]\n",
    "    model = Splade(model_path)\n",
    "    space_tk = BasicTokenizer()\n",
    "    \n",
    "    match_token_splade = []\n",
    "    expand_token_splade = []\n",
    "    match_token_tk = []\n",
    "        \n",
    "    for qid in qids:\n",
    "        query = queries[qid]\n",
    "        top_10_doc = sorted(all_results[model_name][qid].items(), key=lambda x: -x[1])[:10]\n",
    "        t_query_id = model.tokenizer(query, max_length=512, return_tensors=\"pt\")\n",
    "        t_query = model.tokenizer.tokenize(query)\n",
    "        t_query_space = space_tk.tokenize(query)\n",
    "        with torch.no_grad():    \n",
    "            e_query = model.encode(**t_query_id)\n",
    "\n",
    "        top_qrels = []\n",
    "        try:\n",
    "            q_qrels = qrels[qid]\n",
    "        except:\n",
    "            continue\n",
    "        for i, (cid, qrel) in enumerate(q_qrels.items()):            \n",
    "            if qrel > 0:\n",
    "                text = corpus[cid][\"title\"] + \" \" + corpus[cid][\"text\"]\n",
    "                t_text = model.tokenizer.tokenize(text)\n",
    "                # match_token_tk_nums.append(len([t for t in t_query if t in t_text]))\n",
    "                match_type = encode_doc(model, e_query, text, t_query, t_query_space)\n",
    "                match_token_splade += match_type[\"em\"]\n",
    "                expand_token_splade += match_type[\"not-em\"]\n",
    "        \n",
    "\n",
    "    return match_token_splade, expand_token_splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d1be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(corpus, tokenizer):\n",
    "    N = len(corpus)\n",
    "    idf = defaultdict(float)\n",
    "    df = Counter()\n",
    "    for cid, doc in tqdm_notebook(corpus.items()):\n",
    "        text = doc[\"title\"] + \" \" + doc[\"text\"]\n",
    "        t_doc = tokenizer.tokenize(text)\n",
    "        df.update(list(set(t_doc)))\n",
    "    \n",
    "    for v, freq in df.items():\n",
    "        idf[v] = np.log(N/freq)\n",
    "        df[v] = freq / N\n",
    "    return df, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba2cf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a435e0b2b114ad8abdd49b6ac5a1533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"/home/gaia_data/iida.h/BEIR/datasets/msmarco\"\n",
    "ms_corpus, ms_queries, ms_qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8699e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 71694\n",
    "tk_names = [\"splade\", f\"splade-{vocab_size}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ef2041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1352878/3833919760.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for cid, doc in tqdm_notebook(corpus.items()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c059647878084df89dea0017640cb795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720e6cfe1a964aed9bbb43d07c37ac14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ms_tk_df = {}\n",
    "for model_name in tk_names:\n",
    "    df, idf = calc_idf(ms_corpus, tks[model_name])\n",
    "    ms_tk_df[model_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f179e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['splade', 'splade-71694'])\n",
      "dict_keys(['splade', 'splade-71694'])\n"
     ]
    }
   ],
   "source": [
    "print(ms_tk_df.keys())\n",
    "print(tk_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a04ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c13838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1352878/3833919760.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for cid, doc in tqdm_notebook(corpus.items()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a446c33acfb4098bd35e04a10ca22cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c02e7e7f6940f3acdd8930b814c5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tk_df = {}\n",
    "for model_name in tk_names:\n",
    "    df, idf = calc_idf(corpus, tks[model_name])\n",
    "    tk_df[model_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "812a60c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'splade-71684'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1352878/4289577480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mms_tk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"splade-{vocab_size}\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mms_tk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"splade-71684\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"splade-{vocab_size}\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"splade-71684\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'splade-71684'"
     ]
    }
   ],
   "source": [
    "ms_tk_df[f\"splade-{vocab_size}\"] = ms_tk_df[\"splade-71684\"]\n",
    "tk_df[f\"splade-{vocab_size}\"] = tk_df[\"splade-71684\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd201ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_kind_model = {}\n",
    "\n",
    "for model_name in tk_names:\n",
    "    word_kind_model[model_name] = {\"domain_words\": [], \"general_words\": []}\n",
    "    for v in tk_df[model_name]:\n",
    "        if tk_df[model_name][v] > ms_tk_df[model_name].get(v, 0) * 5:\n",
    "            word_kind_model[model_name][\"domain_words\"].append(v)\n",
    "        else:\n",
    "            word_kind_model[model_name][\"general_words\"].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0165d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_expand_words(model_name, expand_token_splade, word_kind_model):\n",
    "    domain_words = []\n",
    "    general_words = []\n",
    "    if str(vocab_size) in model_name:\n",
    "        for w in expand_token_splade:\n",
    "            if w in word_kind_model[f\"splade-{vocab_size}\"][\"domain_words\"]:\n",
    "                domain_words.append(w)\n",
    "            else:\n",
    "                general_words.append(w)\n",
    "    else:\n",
    "        for w in expand_token_splade:\n",
    "            if w in word_kind_model[\"splade\"][\"domain_words\"]:\n",
    "                domain_words.append(w)\n",
    "            else:\n",
    "                general_words.append(w)\n",
    "                \n",
    "    print(f\"expand-domain_words:{len(domain_words)}, expand-general_words:{len(general_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89388407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-71694\n",
      "expand-domain_words:13588, expand-generad_words:12493\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-30522\n",
      "expand-domain_words:6096, expand-generad_words:6028\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade-71694\n",
      "expand-domain_words:10092, expand-generad_words:16738\n",
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_24-2022-04-07_21-45-37/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade\n",
      "expand-domain_words:10613, expand-generad_words:11584\n"
     ]
    }
   ],
   "source": [
    "observe_model = [f\"mlm-splade-{vocab_size}\", \"mlm-splade-30522\", f\"splade-{vocab_size}\", \"splade\"]\n",
    "# observe_model = [\"mlm-splade-62783\", \"splade\"]\n",
    "for model_name in observe_model:\n",
    "    match_token_splade, expand_token_splade = em_w_space_tk(model_name, qids_adalm_splade_better, all_results)\n",
    "    print(model_name)\n",
    "    num_expand_words(model_name, expand_token_splade, word_kind_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "520c20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "147.69565217391303 135.79347826086956\n",
      "66.26086956521739 65.52173913043478\n",
      "109.69565217391305 181.93478260869566\n",
      "115.3586956521739 125.91304347826087\n"
     ]
    }
   ],
   "source": [
    "N = len(qids_adalm_splade_better)\n",
    "print(N)\n",
    "print(13588/N, 12493/N)\n",
    "print(6096/N, 6028/N)\n",
    "print(10092/N, 16738/N)\n",
    "print(10613/N, 11584/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21f2461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--71694-batch_size_40-2022-04-12_08-52-34/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-71694\n",
      "expand-domain_words:33794, expand-generad_words:30305\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model/raw/remove/30522/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-mlm_model-raw-remove--30522-batch_size_24-2022-04-11_23-21-18/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm-splade-30522\n",
      "expand-domain_words:13629, expand-generad_words:12403\n",
      "path /home/gaia_data/iida.h/BEIR/model/pubmed_abst/bert-base-uncased/splade_model_init/raw/remove/71694/distilSplade_0.1_0.08_-groups-gcb50243-iida.h-BEIR-model-pubmed_abst-bert-base-uncased-init_model-raw-remove--71694-batch_size_40-2022-04-24_00-46-31/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade-71694\n",
      "expand-domain_words:24975, expand-generad_words:41281\n",
      "path /home/gaia_data/iida.h/BEIR/model/msmarco/splade/distilSplade_0.1_0.08_bert-base-uncased-batch_size_24-2022-04-07_21-45-37/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splade\n",
      "expand-domain_words:24690, expand-generad_words:25786\n"
     ]
    }
   ],
   "source": [
    "observe_model = [f\"mlm-splade-{vocab_size}\", \"mlm-splade-30522\", f\"splade-{vocab_size}\", \"splade\"]\n",
    "# observe_model = [\"mlm-splade-62783\", \"splade\"]\n",
    "for model_name in observe_model:\n",
    "    match_token_splade, expand_token_splade = em_w_space_tk(model_name, q_index, all_results)\n",
    "    print(model_name)\n",
    "    num_expand_words(model_name, expand_token_splade, word_kind_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e733ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06001d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e598dbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalm</th>\n",
       "      <th>dapt-splade-59372</th>\n",
       "      <th>dapt-59372</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105014</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.099603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.157557</td>\n",
       "      <td>-0.157557</td>\n",
       "      <td>-0.157557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644442</td>\n",
       "      <td>0.545817</td>\n",
       "      <td>0.235547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.209543</td>\n",
       "      <td>-0.468651</td>\n",
       "      <td>-0.387676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087211</td>\n",
       "      <td>0.207809</td>\n",
       "      <td>0.094468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.085162</td>\n",
       "      <td>-0.032012</td>\n",
       "      <td>-0.021541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-0.309806</td>\n",
       "      <td>-0.030386</td>\n",
       "      <td>0.021262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.243098</td>\n",
       "      <td>-0.131470</td>\n",
       "      <td>0.038757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.131090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        adalm  dapt-splade-59372  dapt-59372\n",
       "0    0.105014           0.008879    0.099603\n",
       "1   -0.157557          -0.157557   -0.157557\n",
       "2    0.644442           0.545817    0.235547\n",
       "3   -0.209543          -0.468651   -0.387676\n",
       "4    0.087211           0.207809    0.094468\n",
       "..        ...                ...         ...\n",
       "318 -0.085162          -0.032012   -0.021541\n",
       "319  0.000000           0.000000    0.000000\n",
       "320 -0.309806          -0.030386    0.021262\n",
       "321 -0.243098          -0.131470    0.038757\n",
       "322  0.131090           0.000000    0.000000\n",
       "\n",
       "[323 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff_from_splade = pd.DataFrame(diff_from_splade)\n",
    "df_diff_from_splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "41d5fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalm</th>\n",
       "      <th>dapt-splade-59372</th>\n",
       "      <th>dapt-59372</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.157557</td>\n",
       "      <td>-0.157557</td>\n",
       "      <td>-0.157557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.209543</td>\n",
       "      <td>-0.468651</td>\n",
       "      <td>-0.387676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.083009</td>\n",
       "      <td>-0.279622</td>\n",
       "      <td>-0.273529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.220092</td>\n",
       "      <td>-0.220092</td>\n",
       "      <td>-0.134949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.039513</td>\n",
       "      <td>-0.151762</td>\n",
       "      <td>-0.078398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.059688</td>\n",
       "      <td>-0.158731</td>\n",
       "      <td>0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.074855</td>\n",
       "      <td>-0.167160</td>\n",
       "      <td>-0.220258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.193092</td>\n",
       "      <td>-0.169580</td>\n",
       "      <td>-0.125174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.176018</td>\n",
       "      <td>-0.178651</td>\n",
       "      <td>0.063719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.202774</td>\n",
       "      <td>-0.242394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.445199</td>\n",
       "      <td>-0.330138</td>\n",
       "      <td>0.559816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.548135</td>\n",
       "      <td>-0.294192</td>\n",
       "      <td>-0.621499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.735380</td>\n",
       "      <td>-0.195738</td>\n",
       "      <td>-0.416586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-0.381213</td>\n",
       "      <td>-0.243775</td>\n",
       "      <td>-0.381213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.053976</td>\n",
       "      <td>-0.224006</td>\n",
       "      <td>-0.129973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.095551</td>\n",
       "      <td>-0.185747</td>\n",
       "      <td>-0.217741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.630930</td>\n",
       "      <td>-0.630930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.151320</td>\n",
       "      <td>-0.210811</td>\n",
       "      <td>-0.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.002633</td>\n",
       "      <td>-0.538431</td>\n",
       "      <td>-0.227938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-0.213986</td>\n",
       "      <td>-0.169580</td>\n",
       "      <td>-0.383566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.158409</td>\n",
       "      <td>-0.176300</td>\n",
       "      <td>-0.097902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>-0.017934</td>\n",
       "      <td>-0.153232</td>\n",
       "      <td>0.085457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.002950</td>\n",
       "      <td>-0.179295</td>\n",
       "      <td>-0.150288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.147472</td>\n",
       "      <td>-0.261738</td>\n",
       "      <td>-0.147472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>-0.033365</td>\n",
       "      <td>-0.160783</td>\n",
       "      <td>-0.160783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.003740</td>\n",
       "      <td>-0.181707</td>\n",
       "      <td>-0.048232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-0.369070</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.569323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.012845</td>\n",
       "      <td>-0.237198</td>\n",
       "      <td>-0.455605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.133153</td>\n",
       "      <td>-0.180390</td>\n",
       "      <td>-0.133153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-0.119547</td>\n",
       "      <td>-0.208533</td>\n",
       "      <td>-0.114901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.200409</td>\n",
       "      <td>-0.273577</td>\n",
       "      <td>-0.334690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.302963</td>\n",
       "      <td>-0.295662</td>\n",
       "      <td>-0.154910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        adalm  dapt-splade-59372  dapt-59372\n",
       "1   -0.157557          -0.157557   -0.157557\n",
       "3   -0.209543          -0.468651   -0.387676\n",
       "19  -0.083009          -0.279622   -0.273529\n",
       "22  -0.220092          -0.220092   -0.134949\n",
       "25   0.039513          -0.151762   -0.078398\n",
       "27   0.059688          -0.158731    0.005034\n",
       "28   0.074855          -0.167160   -0.220258\n",
       "34  -0.193092          -0.169580   -0.125174\n",
       "44  -0.176018          -0.178651    0.063719\n",
       "48   0.000000          -0.202774   -0.242394\n",
       "64   0.445199          -0.330138    0.559816\n",
       "80  -0.548135          -0.294192   -0.621499\n",
       "155 -0.735380          -0.195738   -0.416586\n",
       "169 -0.381213          -0.243775   -0.381213\n",
       "173 -0.053976          -0.224006   -0.129973\n",
       "186 -0.095551          -0.185747   -0.217741\n",
       "189  0.000000          -0.630930   -0.630930\n",
       "198  0.151320          -0.210811   -0.481900\n",
       "200  0.002633          -0.538431   -0.227938\n",
       "215 -0.213986          -0.169580   -0.383566\n",
       "218  0.158409          -0.176300   -0.097902\n",
       "225 -0.017934          -0.153232    0.085457\n",
       "226  0.002950          -0.179295   -0.150288\n",
       "228 -0.147472          -0.261738   -0.147472\n",
       "233 -0.033365          -0.160783   -0.160783\n",
       "249 -0.003740          -0.181707   -0.048232\n",
       "280 -0.369070          -0.500000   -0.569323\n",
       "285  0.012845          -0.237198   -0.455605\n",
       "299 -0.133153          -0.180390   -0.133153\n",
       "303 -0.119547          -0.208533   -0.114901\n",
       "306 -0.200409          -0.273577   -0.334690\n",
       "313 -0.302963          -0.295662   -0.154910"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff_from_splade[(df_diff_from_splade[\"dapt-splade-59372\"] < -0.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6474a959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalm</th>\n",
       "      <th>dapt-splade-59372</th>\n",
       "      <th>dapt-59372</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.161957</td>\n",
       "      <td>-0.139502</td>\n",
       "      <td>-0.139502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.057063</td>\n",
       "      <td>-0.113103</td>\n",
       "      <td>-0.044399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.039513</td>\n",
       "      <td>-0.151762</td>\n",
       "      <td>-0.078398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.059688</td>\n",
       "      <td>-0.158731</td>\n",
       "      <td>0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.074855</td>\n",
       "      <td>-0.167160</td>\n",
       "      <td>-0.220258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.445199</td>\n",
       "      <td>-0.330138</td>\n",
       "      <td>0.559816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.258330</td>\n",
       "      <td>-0.112306</td>\n",
       "      <td>0.085143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.059688</td>\n",
       "      <td>-0.114657</td>\n",
       "      <td>-0.098267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.151320</td>\n",
       "      <td>-0.210811</td>\n",
       "      <td>-0.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.002633</td>\n",
       "      <td>-0.538431</td>\n",
       "      <td>-0.227938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.346893</td>\n",
       "      <td>-0.144634</td>\n",
       "      <td>0.157672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.158409</td>\n",
       "      <td>-0.176300</td>\n",
       "      <td>-0.097902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.002950</td>\n",
       "      <td>-0.179295</td>\n",
       "      <td>-0.150288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.238262</td>\n",
       "      <td>-0.138862</td>\n",
       "      <td>-0.181453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.299648</td>\n",
       "      <td>-0.145748</td>\n",
       "      <td>-0.189057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.012845</td>\n",
       "      <td>-0.237198</td>\n",
       "      <td>-0.455605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        adalm  dapt-splade-59372  dapt-59372\n",
       "9    0.161957          -0.139502   -0.139502\n",
       "10   0.057063          -0.113103   -0.044399\n",
       "25   0.039513          -0.151762   -0.078398\n",
       "27   0.059688          -0.158731    0.005034\n",
       "28   0.074855          -0.167160   -0.220258\n",
       "64   0.445199          -0.330138    0.559816\n",
       "75   0.258330          -0.112306    0.085143\n",
       "168  0.059688          -0.114657   -0.098267\n",
       "198  0.151320          -0.210811   -0.481900\n",
       "200  0.002633          -0.538431   -0.227938\n",
       "213  0.346893          -0.144634    0.157672\n",
       "218  0.158409          -0.176300   -0.097902\n",
       "226  0.002950          -0.179295   -0.150288\n",
       "247  0.238262          -0.138862   -0.181453\n",
       "248  0.299648          -0.145748   -0.189057\n",
       "285  0.012845          -0.237198   -0.455605"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff_from_splade[(df_diff_from_splade[\"adalm\"] > 0) & (df_diff_from_splade[\"dapt-splade-59372\"] < -0.1)]\n",
    "# df_diff_from_splade[(df_diff_from_splade[\"dapt-splade-59372\"] < -0.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4fb6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qids_only_adalm_improve = [q_index[159], q_index[198], q_index[239], q_index[248]]\n",
    "# qids_dapt_worse = [q_index[36], q_index[132], q_index[189], q_index[284]]\n",
    "qids_dapt_worse = [q_index[3], q_index[189], q_index[280], q_index[306]]\n",
    "qids_dapt_worse_adalm_better = [q_index[9], q_index[198], q_index[247], q_index[248]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ef4ac21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalm</th>\n",
       "      <th>dapt-splade-59372</th>\n",
       "      <th>dapt-59372</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644442</td>\n",
       "      <td>0.545817</td>\n",
       "      <td>0.235547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087211</td>\n",
       "      <td>0.207809</td>\n",
       "      <td>0.094468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>0.220092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.375670</td>\n",
       "      <td>0.507238</td>\n",
       "      <td>0.183410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.286366</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>0.106889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-0.169580</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>-0.067483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.173187</td>\n",
       "      <td>0.170108</td>\n",
       "      <td>0.188899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.199183</td>\n",
       "      <td>0.298247</td>\n",
       "      <td>0.210534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.914857</td>\n",
       "      <td>0.605095</td>\n",
       "      <td>0.542075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.119021</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.019907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150489</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.020411</td>\n",
       "      <td>0.181292</td>\n",
       "      <td>0.080540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.082398</td>\n",
       "      <td>0.249356</td>\n",
       "      <td>0.050612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281658</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.312852</td>\n",
       "      <td>0.456849</td>\n",
       "      <td>-0.156426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        adalm  dapt-splade-59372  dapt-59372\n",
       "2    0.644442           0.545817    0.235547\n",
       "4    0.087211           0.207809    0.094468\n",
       "26   0.110500           0.179477    0.220092\n",
       "83   0.375670           0.507238    0.183410\n",
       "115  0.286366           0.160385    0.106889\n",
       "142 -0.169580           0.169580   -0.067483\n",
       "193  0.173187           0.170108    0.188899\n",
       "227  0.199183           0.298247    0.210534\n",
       "240  0.914857           0.605095    0.542075\n",
       "267  0.119021           0.252174    0.019907\n",
       "286  0.000000           0.150489    0.000000\n",
       "291  0.020411           0.181292    0.080540\n",
       "304 -0.082398           0.249356    0.050612\n",
       "307  0.000000           0.281658    0.000000\n",
       "309  0.312852           0.456849   -0.156426"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_diff_from_splade[(df_diff_from_splade[\"adalm\"] < 0) & (df_diff_from_splade[\"dapt-59372\"] > 0)]\n",
    "df_diff_from_splade[(df_diff_from_splade[\"dapt-splade-59372\"] > 0.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268cad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_em_w_space_tk(model_name, qids, all_results):\n",
    "    def encode_doc(model, e_query, text, t_query, t_query_space):\n",
    "        t_text = model.tokenizer(text, max_length=512, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            e_text = model.encode(**t_text)\n",
    "            match_scores = e_query * e_text\n",
    "            score, ids = torch.topk(match_scores, k=20)\n",
    "            ids = ids[0][score[0] > 0.1]\n",
    "            score = score[0][score[0] > 0.1]\n",
    "            tids = model.tokenizer.decode(ids)\n",
    "        t_tids = tids.split()\n",
    "        match_type = {\"em\": [], \"not-em\": [], \"space-tk\": []}\n",
    "        not_em = []\n",
    "        for t in t_tids:\n",
    "            if t in t_query:\n",
    "                match_type[\"em\"].append(t)\n",
    "            else:\n",
    "                match_type[\"not-em\"].append(t)\n",
    "         \n",
    "            if t in t_query_space:\n",
    "                match_type[\"space-tk\"].append(t)\n",
    "                \n",
    "        return match_type\n",
    "    \n",
    "    model_path = model_pathes[model_name]\n",
    "    model = Splade(model_path)\n",
    "    space_tk = BasicTokenizer()\n",
    "    \n",
    "    match_token_splade_nums = []\n",
    "    expand_token_splade_nums = []\n",
    "    match_token_tk_nums = []\n",
    "        \n",
    "    for qid in qids:\n",
    "        query = queries[qid]\n",
    "        top_10_doc = sorted(all_results[model_name][qid].items(), key=lambda x: -x[1])[:10]\n",
    "        t_query_id = model.tokenizer(query, max_length=512, return_tensors=\"pt\")\n",
    "        t_query = model.tokenizer.tokenize(query)\n",
    "        t_query_space = space_tk.tokenize(query)\n",
    "        with torch.no_grad():    \n",
    "            e_query = model.encode(**t_query_id)\n",
    "\n",
    "        top_qrels = []\n",
    "        try:\n",
    "            q_qrels = qrels[qid]\n",
    "        except:\n",
    "            continue\n",
    "        for i, (cid, qrel) in enumerate(q_qrels.items()):            \n",
    "            if qrel > 0:\n",
    "                text = corpus[cid][\"title\"] + \" \" + corpus[cid][\"text\"]\n",
    "                t_text = model.tokenizer.tokenize(text)\n",
    "                match_token_tk_nums.append(len([t for t in t_query if t in t_text]))\n",
    "                match_type = encode_doc(model, e_query, text, t_query, t_query_space)\n",
    "                match_token_splade_nums.append(len(match_type[\"em\"]))\n",
    "                expand_token_splade_nums.append(len(match_type[\"not-em\"]))\n",
    "        \n",
    "\n",
    "    return match_token_tk_nums, match_token_splade_nums, expand_token_splade_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "249480c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_em_w_space_tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_330048/1204590011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# observe_model = [\"mlm-splade-62783\", \"splade\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobserve_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmatch_token_tk_nums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_token_splade_nums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_token_splade_nums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_em_w_space_tk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqids_adalm_splade_better\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model_name}, em_tk: {np.mean(match_token_tk_nums)}, em_splade: {np.mean(match_token_splade_nums)}, expand: {np.mean(expand_token_splade_nums)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_em_w_space_tk' is not defined"
     ]
    }
   ],
   "source": [
    "observe_model = [\"mlm-splade-62783\", \"mlm-splade-30522\", \"splade-62783\", \"splade\"]\n",
    "# observe_model = [\"mlm-splade-62783\", \"splade\"]\n",
    "for model_name in observe_model:\n",
    "    match_token_tk_nums, match_token_splade_nums, expand_token_splade_nums = count_em_w_space_tk(model_name, qids_adalm_splade_better, all_results)\n",
    "    print(f\"{model_name}, em_tk: {np.mean(match_token_tk_nums)}, em_splade: {np.mean(match_token_splade_nums)}, expand: {np.mean(expand_token_splade_nums)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b1c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7341c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90cd965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e6b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13b9eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qid_only_dapt_59372_improve = q_index[232]\n",
    "qids_dapt_59372_improve = [q_index[2], q_index[83], q_index[240], q_index[307]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c122d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(model_name, qid, all_results):\n",
    "    def encode_vec(model, e_query, text):\n",
    "        t_text = model.tokenizer(text, max_length=512, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            e_text = model.encode(**t_text)\n",
    "            match_scores = e_query * e_text\n",
    "            score, ids = torch.topk(match_scores, k=20)\n",
    "            ids = ids[0][score[0] > 0.1]\n",
    "            score = score[0][score[0] > 0.1]\n",
    "            tids = model.tokenizer.decode(ids)\n",
    "        print([round(s, 2) for s in score.tolist()])\n",
    "        print(tids)\n",
    "    \n",
    "    model_path = model_pathes[model_name]\n",
    "    query = queries[qid]\n",
    "    top_10_doc = sorted(all_results[model_name][qid].items(), key=lambda x: -x[1])[:10]\n",
    "    model = Splade(model_path)\n",
    "    t_query = model.tokenizer(query, max_length=512, return_tensors=\"pt\")\n",
    "    with torch.no_grad():    \n",
    "        e_query = model.encode(**t_query)\n",
    "    for i, (cid, score) in enumerate(top_10_doc):\n",
    "        try:\n",
    "            qrel = qrels[qid][cid]\n",
    "        except:\n",
    "            qrel = \"not-eval\"\n",
    "        print(i, cid, score, qrel)\n",
    "        text = corpus[cid][\"title\"] + \" \" + corpus[cid][\"text\"]\n",
    "        encode_vec(model, e_query, text)\n",
    "        \n",
    "    del model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2926ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "What’s Driving America’s Obesity Problem?\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-5006 96.15606689453125 not-eval\n",
      "[6.29, 4.79, 3.97, 3.86, 3.76, 3.41, 3.22, 2.95, 2.86, 2.8, 2.68, 2.36, 2.17, 2.02, 1.96, 1.84, 1.82, 1.81, 1.74, 1.68]\n",
      "obesity obese bmi overweight epidemic american adiposity us fatness prevalence weight usa americans america problem fat ow national cost south\n",
      "1 MED-2723 87.42149353027344 2\n",
      "[6.51, 4.82, 3.42, 3.24, 3.19, 3.01, 2.96, 2.95, 2.87, 2.51, 2.41, 2.14, 1.98, 1.96, 1.73, 1.69, 1.6, 1.49, 1.42, 1.41]\n",
      "obesity obese epidemic adiposity weight bmi usa fatness overweight us prevalence american fat economic ow cost national osa mass south\n",
      "2 MED-1328 80.39183044433594 not-eval\n",
      "[6.43, 4.56, 4.01, 3.93, 3.28, 3.12, 2.91, 2.83, 2.64, 2.36, 2.34, 2.09, 1.88, 1.86, 1.84, 1.68, 1.59, 1.54, 1.51, 1.4]\n",
      "obesity obese bmi overweight adiposity prevalence fatness epidemic weight country national ow mass american fat us south youth body android\n",
      "3 MED-1448 77.73985290527344 not-eval\n",
      "[6.48, 4.84, 3.54, 3.35, 3.15, 3.03, 2.46, 2.18, 1.98, 1.98, 1.95, 1.93, 1.9, 1.84, 1.79, 1.67, 1.65, 1.59, 1.52, 1.51]\n",
      "obesity obese overweight adiposity fatness bmi weight fat ow epidemic cost prevalence mass economic us osa expenditure body usa android\n",
      "4 MED-2722 77.30563354492188 1\n",
      "[6.38, 4.43, 3.71, 3.25, 3.09, 2.93, 2.8, 2.69, 2.59, 2.57, 2.34, 2.33, 2.19, 1.73, 1.69, 1.64, 1.53, 1.46, 1.43, 1.42]\n",
      "obesity obese bmi adiposity fatness us prevalence overweight american epidemic fat weight usa mass running national country south body ow\n",
      "5 MED-1056 72.74028015136719 not-eval\n",
      "[6.26, 4.3, 3.48, 3.06, 2.91, 2.66, 2.57, 2.3, 2.22, 2.0, 1.95, 1.94, 1.91, 1.69, 1.68, 1.58, 1.5, 1.49, 1.28, 1.25]\n",
      "obesity obese epidemic overweight adiposity fatness bmi country weight south american fat pandemic problem national ow prevalence america western us\n",
      "6 MED-1650 72.53010559082031 not-eval\n",
      "[6.11, 4.19, 3.93, 2.81, 2.65, 2.65, 2.46, 2.46, 2.31, 2.17, 2.05, 1.74, 1.63, 1.58, 1.58, 1.56, 1.51, 1.51, 1.48, 1.3]\n",
      "obesity obese epidemic adiposity bmi fatness overweight prevalence weight fat problem national country ow american pandemic us youth energy lean\n",
      "7 MED-2721 70.77355194091797 2\n",
      "[6.14, 4.25, 3.53, 3.51, 3.04, 2.95, 2.7, 2.67, 2.52, 2.46, 2.31, 2.14, 2.06, 1.61, 1.46, 1.45, 1.42, 1.33, 1.32, 1.27]\n",
      "obesity obese epidemic weight adiposity us overweight fatness bmi energy american fat usa ow expenditure body prevalence youth lean mass\n",
      "8 MED-1334 68.77295684814453 not-eval\n",
      "[6.3, 4.44, 3.82, 3.03, 2.89, 2.81, 2.58, 2.47, 2.04, 1.91, 1.91, 1.86, 1.85, 1.82, 1.51, 1.49, 1.46, 1.45, 1.29, 1.27]\n",
      "obesity obese overweight bmi adiposity fatness epidemic weight prevalence national fat ow western problem country south youth android lean osa\n",
      "9 MED-2162 62.88834762573242 not-eval\n",
      "[6.17, 4.54, 3.9, 3.45, 3.43, 3.38, 3.2, 2.37, 1.99, 1.99, 1.92, 1.74, 1.42, 1.39, 1.36, 1.26, 1.23, 1.2, 1.18, 1.15]\n",
      "obesity obese overweight adiposity bmi weight fatness mass body fat us ow morbidly american epidemic android anthropometric excess image lean\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-1334 6.441590309143066 not-eval\n",
      "[4.72, 1.57, 0.15]\n",
      "obesity ’ heather\n",
      "1 MED-1056 5.927430152893066 not-eval\n",
      "[4.29, 1.64]\n",
      "obesity ’\n",
      "2 MED-1213 5.682057857513428 not-eval\n",
      "[3.12, 1.48, 0.1]\n",
      "obesity ’ s\n",
      "3 MED-1790 5.591947078704834 not-eval\n",
      "[3.73, 1.46, 0.38]\n",
      "obesity ’ heather\n",
      "4 MED-4766 4.918933868408203 not-eval\n",
      "[4.92]\n",
      "obesity\n",
      "5 MED-4776 4.743581771850586 not-eval\n",
      "[4.82]\n",
      "obesity\n",
      "6 MED-4768 4.7081298828125 not-eval\n",
      "[4.71]\n",
      "obesity\n",
      "7 MED-1446 4.700077533721924 not-eval\n",
      "[3.96, 0.38]\n",
      "obesity ’\n",
      "8 MED-1800 4.588093280792236 not-eval\n",
      "[4.33]\n",
      "obesity\n",
      "9 MED-3052 4.565436363220215 not-eval\n",
      "[4.71]\n",
      "obesity\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-1334 26.859657287597656 not-eval\n",
      "[7.61, 2.79, 1.91, 1.72, 1.71, 1.29, 1.26, 1.23, 1.05, 0.95, 0.91, 0.83, 0.79, 0.77, 0.75, 0.71, 0.26, 0.11]\n",
      "obesity disease illness shell retirement residents family strategies histories s obese repeated staffing contemplating riding initiation bird ventilation\n",
      "1 MED-3058 22.74083709716797 not-eval\n",
      "[7.87, 2.66, 2.19, 1.53, 1.39, 1.22, 1.07, 1.01, 0.86, 0.86, 0.49, 0.46, 0.36, 0.33, 0.21, 0.12]\n",
      "obesity disease illness retirement family contemplating strategies shell obese repeated histories respiratory promises staffing sandhoff residents\n",
      "2 MED-1230 22.467411041259766 not-eval\n",
      "[7.53, 2.56, 1.77, 1.27, 1.24, 0.97, 0.95, 0.9, 0.83, 0.81, 0.8, 0.79, 0.65, 0.64, 0.31, 0.23, 0.1]\n",
      "obesity retirement shell illness disease strategies repeated initiation family staffing histories residents contemplating obese riding promises ventilation\n",
      "3 MED-1650 21.633207321166992 not-eval\n",
      "[7.23, 2.16, 1.77, 1.68, 1.39, 1.3, 1.02, 1.02, 0.97, 0.8, 0.55, 0.51, 0.45, 0.39, 0.39]\n",
      "obesity disease contemplating shell initiation illness family retirement residents histories strategies respiratory bird obese staffing\n",
      "4 MED-1331 21.224361419677734 not-eval\n",
      "[7.51, 2.67, 1.94, 1.62, 1.56, 1.37, 1.05, 0.95, 0.76, 0.73, 0.69, 0.56, 0.42]\n",
      "obesity disease shell retirement illness family residents histories initiation bird obese strategies staffing\n",
      "5 MED-2723 20.990739822387695 2\n",
      "[7.3, 2.74, 1.75, 1.4, 1.26, 1.19, 1.11, 1.03, 0.95, 0.63, 0.58, 0.51, 0.28, 0.11, 0.11]\n",
      "obesity disease shell retirement illness obese residents histories family staffing repeated strategies promises initiation sandhoff\n",
      "6 MED-1448 20.96978759765625 not-eval\n",
      "[7.52, 1.98, 1.85, 1.54, 1.3, 1.25, 1.05, 1.04, 0.87, 0.76, 0.68, 0.48, 0.32, 0.15, 0.15]\n",
      "obesity retirement disease illness obese shell family residents strategies histories staffing repeated bird promises ventilation\n",
      "7 MED-1803 20.52071189880371 not-eval\n",
      "[7.61, 2.78, 1.63, 1.42, 1.34, 1.08, 1.07, 0.78, 0.74, 0.71, 0.5, 0.36, 0.33]\n",
      "obesity disease illness shell family strategies residents obese retirement histories initiation staffing promises\n",
      "8 MED-1056 20.43640899658203 not-eval\n",
      "[7.09, 1.78, 1.77, 1.52, 1.49, 1.2, 1.0, 0.89, 0.84, 0.74, 0.57, 0.55, 0.37, 0.29, 0.13, 0.12]\n",
      "obesity shell disease residents retirement strategies family illness repeated histories staffing obese s bird promises riding\n",
      "9 MED-2216 19.32950782775879 not-eval\n",
      "[5.96, 4.06, 3.66, 1.45, 1.28, 1.03, 0.98, 0.79, 0.36, 0.31]\n",
      "obesity s disease illness residents retirement shell histories staffing repeated\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2721 22.93025779724121 2\n",
      "[5.25, 2.72, 2.71, 2.61, 2.5, 1.28, 1.15, 1.12, 0.86, 0.77, 0.39, 0.29, 0.23, 0.2, 0.19, 0.15]\n",
      "obesity weight obe fat driving driver cause population united problem drive us food why health child\n",
      "1 MED-2723 21.863014221191406 2\n",
      "[5.41, 3.18, 2.91, 2.8, 1.42, 1.37, 1.25, 1.01, 0.53, 0.48, 0.38, 0.33, 0.2, 0.16]\n",
      "obesity obe fat weight problem cause united population health problems economic why issue us\n",
      "2 MED-1994 21.481243133544922 not-eval\n",
      "[5.11, 2.94, 2.53, 2.08, 1.97, 1.56, 1.35, 1.17, 0.86, 0.68, 0.41, 0.22, 0.11]\n",
      "obesity obe fat weight problem cause united american problems population health child us\n",
      "3 MED-2717 21.0533504486084 2\n",
      "[5.02, 2.87, 2.73, 2.54, 1.95, 1.65, 1.35, 1.1, 0.79, 0.46, 0.28, 0.23, 0.18, 0.14, 0.13]\n",
      "obesity obe weight fat problem united cause problems american health population why us do police\n",
      "4 MED-3057 20.854196548461914 not-eval\n",
      "[5.41, 3.58, 2.78, 2.2, 1.75, 1.38, 1.24, 1.07, 0.38, 0.33, 0.28, 0.14, 0.13, 0.12]\n",
      "obesity obe fat weight drive cause driving problem problems health food why pollution police\n",
      "5 MED-1468 20.54185676574707 not-eval\n",
      "[5.19, 4.2, 2.95, 2.21, 1.91, 1.35, 0.94, 0.93, 0.4, 0.2, 0.15]\n",
      "obesity fat obe weight problem cause population problems health why child\n",
      "6 MED-5006 20.513229370117188 not-eval\n",
      "[5.28, 3.55, 2.73, 2.59, 1.44, 1.26, 1.18, 1.1, 0.47, 0.27, 0.14, 0.13]\n",
      "obesity obe fat weight united cause population american health us child?\n",
      "7 MED-4100 19.87958526611328 not-eval\n",
      "[5.63, 3.31, 2.81, 2.65, 1.81, 1.38, 1.3, 0.41, 0.25, 0.14]\n",
      "obesity obe fat weight cause problem problems health why police\n",
      "8 MED-1718 18.872745513916016 not-eval\n",
      "[5.81, 3.98, 3.12, 2.5, 1.79, 0.65, 0.22, 0.15, 0.12, 0.11, 0.1]\n",
      "obesity obe fat weight cause problems population health causes food why\n",
      "9 MED-4202 18.366579055786133 not-eval\n",
      "[5.29, 2.91, 2.61, 2.48, 1.97, 1.08, 0.83, 0.78, 0.48, 0.28, 0.18, 0.15, 0.13]\n",
      "obesity obe fat weight cause driving problems drive problem'why causes health\n",
      "----------------------------\n",
      "shelf life\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4357 30.825288772583008 not-eval\n",
      "[3.6, 2.85, 2.45, 2.19, 1.73, 1.67, 1.46, 1.38, 1.3, 1.09, 1.04, 1.01, 0.87, 0.8, 0.68, 0.68, 0.56, 0.56, 0.55, 0.52]\n",
      "preservative spoilage preservation storage frozen salad survival cryopreservation refrigerated cold meat preservatives drying microbial coq freezing thermal food browning foods\n",
      "1 MED-4303 28.183612823486328 1\n",
      "[4.0, 2.68, 2.4, 2.39, 2.22, 1.82, 1.69, 1.19, 1.1, 0.87, 0.86, 0.82, 0.79, 0.6, 0.6, 0.58, 0.57, 0.57, 0.52, 0.51]\n",
      "shelf storage life stability spoilage preservative stored salad period aging time survival frozen coq aged browning year store commercial long\n",
      "2 MED-4408 26.780250549316406 not-eval\n",
      "[2.83, 2.17, 1.93, 1.83, 1.51, 1.28, 1.19, 1.14, 1.0, 0.93, 0.91, 0.85, 0.8, 0.78, 0.77, 0.64, 0.53, 0.51, 0.48, 0.48]\n",
      "storage spoilage preservative salad frozen stored refrigerated cold coq product meat browning stability cryopreservation drying thermal freeze horticultural freezing aroma\n",
      "3 MED-1070 26.17877197265625 not-eval\n",
      "[2.87, 2.38, 2.08, 1.81, 1.61, 1.6, 1.55, 1.46, 1.21, 1.14, 1.14, 1.12, 1.09, 1.01, 0.85, 0.54, 0.45, 0.4, 0.36, 0.35]\n",
      "life lifespan longevity storage long survival lifetime aging period old year years aged age time longer browning culture t1 stability\n",
      "4 MED-887 24.362876892089844 not-eval\n",
      "[3.42, 2.51, 1.73, 1.63, 1.61, 1.48, 1.15, 1.0, 0.79, 0.72, 0.66, 0.59, 0.56, 0.53, 0.49, 0.47, 0.39, 0.39, 0.38, 0.37]\n",
      "storage stored salad spoilage preservative frozen cryopreservation preservation store drying browning sweet time refrigerated period vegetables year foods horticultural taste\n",
      "5 MED-2505 23.838871002197266 not-eval\n",
      "[3.9, 2.2, 1.92, 1.7, 1.47, 1.47, 1.44, 1.32, 1.26, 1.21, 1.19, 0.91, 0.89, 0.8, 0.67, 0.61, 0.39, 0.36]\n",
      "life longevity lifespan survival lifetime year years coq long old aging age period aged time longer duration last\n",
      "6 MED-3171 23.493301391601562 not-eval\n",
      "[2.52, 2.39, 2.04, 1.8, 1.65, 1.42, 1.35, 1.18, 1.06, 1.01, 0.97, 0.87, 0.81, 0.81, 0.73, 0.67, 0.46, 0.46, 0.36, 0.3]\n",
      "storage frozen survival preservative cryopreservation stored cold preservation meat freezing refrigerated drying thermal freeze culture spoilage temperature time samples sample\n",
      "7 MED-917 23.451387405395508 not-eval\n",
      "[3.1, 2.46, 2.0, 1.84, 1.22, 1.19, 1.17, 1.14, 1.03, 1.01, 0.87, 0.74, 0.6, 0.59, 0.55, 0.51, 0.47, 0.35, 0.33, 0.31]\n",
      "storage frozen stored cryopreservation preservative cold coq preservation freezing drying freeze tocopherol ras aging browning ice store thermal antioxidant samples\n",
      "8 MED-2514 22.07502555847168 not-eval\n",
      "[3.11, 2.6, 2.39, 1.96, 1.81, 1.47, 1.43, 1.22, 1.05, 0.91, 0.82, 0.8, 0.74, 0.43, 0.41, 0.28, 0.26, 0.14, 0.12]\n",
      "life longevity lifespan survival aging lifetime old long years age year time aged period longer duration ras last decay\n",
      "9 MED-2325 21.184162139892578 not-eval\n",
      "[3.0, 2.58, 2.49, 1.89, 1.6, 1.32, 1.28, 1.05, 0.97, 0.9, 0.77, 0.69, 0.6, 0.54, 0.49, 0.44, 0.41, 0.18]\n",
      "life longevity lifespan survival aging long lifetime old period age time aged longer years duration food yeast last\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2700 7.492215633392334 not-eval\n",
      "[3.84, 1.88, 1.28]\n",
      "shelf long life\n",
      "1 MED-2505 6.846803188323975 not-eval\n",
      "[4.01, 2.78]\n",
      "life long\n",
      "2 MED-2510 5.706483364105225 not-eval\n",
      "[5.08, 0.63]\n",
      "life long\n",
      "3 MED-2502 5.1118998527526855 not-eval\n",
      "[5.11]\n",
      "life\n",
      "4 MED-2325 5.002642631530762 not-eval\n",
      "[4.61, 0.39]\n",
      "life long\n",
      "5 MED-1952 4.958324432373047 not-eval\n",
      "[4.18, 0.78]\n",
      "life long\n",
      "6 MED-2514 4.811100482940674 not-eval\n",
      "[3.41, 1.4]\n",
      "life long\n",
      "7 MED-1070 4.5809760093688965 not-eval\n",
      "[2.65, 1.92]\n",
      "life long\n",
      "8 MED-4919 4.415694236755371 not-eval\n",
      "[2.64, 2.04]\n",
      "life long\n",
      "9 MED-4180 4.351253509521484 not-eval\n",
      "[3.0, 1.37]\n",
      "life long\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2505 17.576492309570312 not-eval\n",
      "[7.11, 2.15, 1.79, 1.31, 1.18, 1.04, 0.97, 0.6, 0.55, 0.27, 0.21, 0.1]\n",
      "life age retirement death staffing exposures repeated arousal durations strategies brains organised\n",
      "1 MED-2510 16.682422637939453 not-eval\n",
      "[6.36, 1.87, 1.53, 1.32, 1.09, 1.06, 0.99, 0.8, 0.67, 0.66, 0.33]\n",
      "life age exposures retirement repeated arousal load staffing death durations strategies\n",
      "2 MED-4697 16.29548454284668 not-eval\n",
      "[5.75, 2.93, 1.81, 1.52, 1.49, 1.36, 0.78, 0.39, 0.25]\n",
      "life age retirement ageing repeated exposures staffing strategies durations\n",
      "3 MED-2514 15.457735061645508 not-eval\n",
      "[5.29, 2.77, 1.69, 1.46, 1.42, 1.22, 0.9, 0.44, 0.28]\n",
      "life age repeated exposures retirement ageing staffing arousal strategies\n",
      "4 MED-1914 15.213075637817383 not-eval\n",
      "[5.83, 2.02, 1.86, 1.71, 0.79, 0.7, 0.63, 0.61, 0.56, 0.5]\n",
      "life repeated age exposures death staffing arousal retirement ageing organised\n",
      "5 MED-1922 14.97846794128418 not-eval\n",
      "[4.25, 2.23, 1.87, 1.42, 1.22, 1.15, 1.11, 0.79, 0.51, 0.23, 0.21]\n",
      "life repeated age retirement arousal staffing exposures death organised durations ageing\n",
      "6 MED-1498 14.693672180175781 not-eval\n",
      "[3.68, 2.26, 1.75, 1.41, 1.08, 0.99, 0.95, 0.88, 0.56, 0.45, 0.38, 0.29]\n",
      "life retirement staffing exposures arousal age repeated brains ageing strategies durations organised\n",
      "7 MED-2303 14.096431732177734 not-eval\n",
      "[6.7, 1.84, 1.67, 1.2, 1.1, 0.7, 0.35, 0.33, 0.2]\n",
      "life retirement staffing age repeated exposures death strategies organised\n",
      "8 MED-1933 14.07326889038086 not-eval\n",
      "[4.27, 2.04, 1.63, 1.5, 1.38, 1.36, 1.04, 0.69, 0.17]\n",
      "life repeated retirement ageing age exposures arousal staffing strategies\n",
      "9 MED-2309 13.6559476852417 not-eval\n",
      "[7.13, 1.73, 1.71, 1.01, 0.91, 0.5, 0.17]\n",
      "life death age retirement repeated ageing staffing\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2700 15.191583633422852 not-eval\n",
      "[5.44, 4.01, 2.06, 0.81, 0.47, 0.2, 0.19, 0.15, 0.11, 0.11, 0.1]\n",
      "shelf life shelves long stilllife keep... store it live\n",
      "1 MED-4303 15.027681350708008 1\n",
      "[5.8, 5.16, 1.9, 0.7, 0.6, 0.54, 0.28]\n",
      "shelf life shelves long gracelife store\n",
      "2 MED-2505 11.065703392028809 not-eval\n",
      "[5.53, 2.1, 1.4, 0.57, 0.54, 0.46]\n",
      "life long gracelife live when\n",
      "3 MED-1182 10.135115623474121 not-eval\n",
      "[4.6, 3.04, 1.5, 0.18, 0.17, 0.16, 0.12]\n",
      "shelf life shelves grace... still market\n",
      "4 MED-2671 9.940768241882324 not-eval\n",
      "[4.6, 3.28, 1.73, 0.15, 0.11]\n",
      "shelf life shelves still save\n",
      "5 MED-2074 9.73982048034668 not-eval\n",
      "[4.11, 2.62, 1.08, 0.38, 0.38, 0.2, 0.14, 0.13, 0.1]\n",
      "shelf life shelves store long keep - still that\n",
      "6 MED-859 9.663884162902832 not-eval\n",
      "[4.59, 2.53, 1.94]\n",
      "shelf life shelves\n",
      "7 MED-3270 9.459063529968262 not-eval\n",
      "[4.85, 1.75, 0.72, 0.44, 0.37, 0.29, 0.2]\n",
      "life long gracelife live when still\n",
      "8 MED-4180 9.246498107910156 not-eval\n",
      "[4.91, 1.55, 0.65, 0.56, 0.55, 0.51, 0.23, 0.11]\n",
      "life long when gracelife live this -\n",
      "9 MED-2514 8.757855415344238 not-eval\n",
      "[5.1, 1.7, 0.85, 0.55, 0.45]\n",
      "life long gracelife live\n",
      "----------------------------\n",
      "Vitamin C-Enriched Bacon\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-5188 82.81645202636719 not-eval\n",
      "[8.55, 3.89, 2.97, 2.62, 2.57, 2.55, 2.41, 2.41, 2.4, 2.4, 2.36, 2.12, 2.1, 2.05, 2.01, 1.77, 1.76, 1.65, 1.6, 1.51]\n",
      "bacon meat pork nitrosamine beef belli ham burnt fried sausage ipi pizza fry fin sliced carcass combustion tuberculin browning nitrosamines\n",
      "1 MED-4470 80.79167175292969 2\n",
      "[6.41, 5.1, 4.94, 3.71, 3.66, 2.84, 2.75, 2.5, 2.48, 2.46, 1.99, 1.99, 1.92, 1.87, 1.82, 1.71, 1.64, 1.64, 1.6, 1.58]\n",
      "vitamin c vitamins tocopherol vit coq antioxidants antioxidant riboflavin nitrosamine ascorbic cc carotene salad carbon vc trolox bmc v pyridoxine\n",
      "2 MED-936 79.09519958496094 not-eval\n",
      "[6.36, 5.31, 4.35, 3.67, 3.45, 2.93, 2.86, 2.39, 2.32, 2.3, 2.24, 2.17, 2.03, 1.95, 1.93, 1.88, 1.77, 1.74, 1.68, 1.67]\n",
      "vitamin c vitamins vit tocopherol ascorbate coq antioxidants ascorbic riboflavin antioxidant cc cholecalcifero ca vc carbon bmc supplemental trolox pyridoxine\n",
      "3 MED-4976 77.41629028320312 not-eval\n",
      "[7.44, 3.42, 3.39, 3.29, 3.14, 2.98, 2.44, 2.44, 2.41, 2.34, 2.32, 2.04, 2.02, 1.92, 1.82, 1.81, 1.76, 1.7, 1.59, 1.5]\n",
      "bacon pork beef fried fry meat combustion phip burnt browning fin tuberculin salad nitrosamine pizza ham ipi sausage steak belli\n",
      "4 MED-3157 73.12781524658203 not-eval\n",
      "[6.45, 5.39, 4.33, 3.72, 3.56, 2.84, 2.35, 2.22, 2.19, 2.16, 2.15, 2.1, 2.08, 2.0, 1.93, 1.86, 1.63, 1.58, 1.56, 1.53]\n",
      "vitamin c vitamins vit tocopherol coq antioxidant cc cholecalcifero antioxidants riboflavin vc bmc supplemental carbon ascorbic trolox ci ca v\n",
      "5 MED-4929 71.00975799560547 not-eval\n",
      "[6.35, 4.97, 4.94, 4.11, 3.56, 2.6, 2.51, 2.25, 2.22, 2.04, 1.92, 1.88, 1.85, 1.79, 1.74, 1.67, 1.61, 1.6, 1.57, 1.53]\n",
      "vitamin vitamins c tocopherol vit coq antioxidants riboflavin antioxidant cholecalcifero cc tocopheryl trolox bmc ve vc supplemental pyridoxine retinol carotene\n",
      "6 MED-3453 70.78701782226562 not-eval\n",
      "[6.26, 4.95, 4.41, 3.63, 3.51, 3.48, 3.31, 2.96, 2.08, 1.97, 1.94, 1.94, 1.91, 1.8, 1.65, 1.54, 1.47, 1.45, 1.44, 1.42]\n",
      "vitamin c vitamins tocopherol vit antioxidants antioxidant coq riboflavin cc vc ascorbic ascorbate trolox cholecalcifero bmc ca ci carotene carbon\n",
      "7 MED-4928 65.06767272949219 not-eval\n",
      "[6.06, 4.62, 4.53, 4.2, 4.11, 3.79, 3.31, 3.02, 2.95, 2.49, 2.08, 2.02, 1.99, 1.88, 1.73, 1.57, 1.5, 1.4, 1.37, 1.28]\n",
      "vitamin vitamins c tocopherol antioxidants antioxidant vit carotene coq ascorbic ascorbate carotenoid trolox supplemental riboflavin supplementation tocopheryl cc ci b\n",
      "8 MED-1601 62.001380920410156 not-eval\n",
      "[7.18, 4.4, 4.19, 3.26, 2.71, 2.54, 2.34, 2.12, 2.0, 1.85, 1.7, 1.41, 1.33, 1.14, 1.13, 1.12, 1.09, 1.07, 1.06, 1.02]\n",
      "bacon c ham meat sausage browning pork nitrosamine nitrite beef product nitrosation carcass industry salad combustion fin tuberculin burnt fat\n",
      "9 MED-3452 61.540321350097656 not-eval\n",
      "[6.1, 5.07, 4.14, 3.83, 3.82, 3.8, 3.41, 2.58, 2.29, 1.85, 1.68, 1.68, 1.66, 1.42, 1.37, 1.36, 1.34, 1.27, 1.18, 1.1]\n",
      "vitamin vitamins c antioxidants antioxidant tocopherol vit coq riboflavin supplemental supplementation ascorbate trolox carotene v cholecalcifero ascorbic retinol ve pyridoxine\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4929 9.187414169311523 not-eval\n",
      "[4.01, 3.39, 1.84]\n",
      "c vitamin vitamins\n",
      "1 MED-3157 9.155698776245117 not-eval\n",
      "[4.53, 3.46, 1.16]\n",
      "c vitamin vitamins\n",
      "2 MED-4470 8.958252906799316 2\n",
      "[4.29, 3.01, 1.66]\n",
      "c vitamin vitamins\n",
      "3 MED-936 8.249692916870117 not-eval\n",
      "[4.45, 2.93, 0.98]\n",
      "c vitamin vitamins\n",
      "4 MED-3453 7.881024360656738 not-eval\n",
      "[4.02, 2.94, 1.14]\n",
      "c vitamin vitamins\n",
      "5 MED-4928 7.799522399902344 not-eval\n",
      "[3.39, 3.1, 1.54]\n",
      "c vitamin vitamins\n",
      "6 MED-2453 7.691823959350586 not-eval\n",
      "[3.29, 2.79, 0.98]\n",
      "c vitamin vitamins\n",
      "7 MED-3452 7.060169219970703 not-eval\n",
      "[3.16, 1.97, 1.85]\n",
      "vitamin c vitamins\n",
      "8 MED-1601 6.994338035583496 not-eval\n",
      "[6.25, 0.5, 0.15]\n",
      "bacon c bark\n",
      "9 MED-917 6.599853515625 not-eval\n",
      "[3.01, 2.43, 1.03]\n",
      "c vitamin vitamins\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3157 15.02502727508545 not-eval\n",
      "[7.35, 5.59, 1.26, 0.48, 0.27]\n",
      "vitamin c vitamins - b2\n",
      "1 MED-4929 14.733606338500977 not-eval\n",
      "[7.36, 4.96, 1.91, 0.47]\n",
      "vitamin c vitamins b2\n",
      "2 MED-936 14.227548599243164 not-eval\n",
      "[7.1, 5.72, 1.06]\n",
      "vitamin c vitamins\n",
      "3 MED-4470 13.93807601928711 2\n",
      "[7.28, 4.18, 1.98, 0.5]\n",
      "vitamin c vitamins b2\n",
      "4 MED-2946 13.502647399902344 not-eval\n",
      "[7.61, 2.34, 1.45, 1.41, 0.25, 0.23]\n",
      "vitamin c - vitamins b2 b\n",
      "5 MED-3453 12.772061347961426 not-eval\n",
      "[7.38, 4.77, 1.21]\n",
      "vitamin c vitamins\n",
      "6 MED-920 12.419580459594727 not-eval\n",
      "[7.43, 3.32, 0.58, 0.52, 0.46, 0.1]\n",
      "vitamin c b2 vitamins - b\n",
      "7 MED-2453 12.126818656921387 not-eval\n",
      "[6.66, 4.92, 0.63]\n",
      "vitamin c vitamins\n",
      "8 MED-4928 11.903697967529297 not-eval\n",
      "[6.95, 3.75, 1.82]\n",
      "vitamin c vitamins\n",
      "9 MED-4570 11.796016693115234 not-eval\n",
      "[7.3, 2.19, 1.22, 1.03, 0.44]\n",
      "vitamin c vitamins - b2\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4470 15.641761779785156 2\n",
      "[5.94, 4.73, 1.71, 1.19, 0.87, 0.47, 0.42, 0.13, 0.1]\n",
      "vitamin c brooke food for drug contain, eat\n",
      "1 MED-3157 15.581504821777344 not-eval\n",
      "[5.85, 5.16, 1.62, 1.15, 0.91, 0.49, 0.12]\n",
      "vitamin c brooke food for drug eat\n",
      "2 MED-1601 14.826390266418457 not-eval\n",
      "[6.28, 2.75, 2.34, 1.64, 0.76, 0.53, 0.22]\n",
      "bacon c henry food for vitamin contain\n",
      "3 MED-917 14.680298805236816 not-eval\n",
      "[5.12, 3.94, 1.4, 1.15, 0.72, 0.54, 0.53, 0.45, 0.28]\n",
      "vitamin c food brooke for rich drug contain him\n",
      "4 MED-4928 14.316770553588867 not-eval\n",
      "[5.26, 3.84, 1.41, 1.17, 0.74, 0.57, 0.52, 0.25, 0.12, 0.1]\n",
      "vitamin c brooke food drug for rich contain, eat\n",
      "5 MED-3453 13.765913009643555 not-eval\n",
      "[5.48, 4.17, 1.75, 0.73, 0.67, 0.5, 0.17, 0.16, 0.13]\n",
      "vitamin c brooke for drug food, him contain\n",
      "6 MED-936 13.694149017333984 not-eval\n",
      "[5.43, 4.62, 1.43, 0.65, 0.57, 0.24, 0.19, 0.11]\n",
      "vitamin c brooke for drug food, amount\n",
      "7 MED-3024 13.395315170288086 not-eval\n",
      "[4.11, 2.58, 2.0, 1.36, 0.83, 0.53, 0.45, 0.43, 0.18, 0.17, 0.12, 0.11, 0.1]\n",
      "vitamin c enriched food brooke enrichment for drug contain him, in eat\n",
      "8 MED-4929 13.372974395751953 not-eval\n",
      "[5.9, 4.02, 1.73, 0.69, 0.63, 0.14, 0.11]\n",
      "vitamin c brooke for drug, amount\n",
      "9 MED-3452 13.113851547241211 not-eval\n",
      "[5.89, 2.91, 1.64, 1.21, 0.57, 0.55]\n",
      "vitamin c brooke food drug for\n",
      "----------------------------\n",
      "Sexually Transmitted Fish Toxin\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4360 90.87442016601562 not-eval\n",
      "[4.41, 4.01, 3.46, 3.45, 3.09, 2.94, 2.87, 2.71, 2.61, 2.51, 2.32, 2.22, 2.13, 2.13, 2.1, 2.05, 1.96, 1.78, 1.78, 1.75]\n",
      "toxin fish sexually sexual toxins transmitted toxic toxicant neurotoxin neurotoxic male transmission mycotoxin semen sex toxicity transmissible contaminant contaminated infectious\n",
      "1 MED-1572 76.14779663085938 1\n",
      "[5.57, 4.29, 3.66, 3.24, 3.19, 2.77, 2.71, 2.48, 2.43, 1.87, 1.64, 1.61, 1.59, 1.56, 1.49, 1.46, 1.42, 1.36, 1.35, 1.29]\n",
      "fish toxin toxins fishes toxic neurotoxic neurotoxin toxicant fin toxicity seafood shellfish neurotoxicity poisoning marine contaminant spawning hazardous contaminated toxicants\n",
      "2 MED-4739 71.01115417480469 not-eval\n",
      "[4.13, 3.47, 3.42, 2.91, 2.6, 2.45, 2.43, 2.36, 2.34, 2.26, 2.08, 2.05, 1.99, 1.83, 1.77, 1.76, 1.63, 1.59, 1.58, 1.47]\n",
      "toxicant fish toxic toxicants toxin seafood neurotoxic toxicity contaminant chemicals mycotoxin marine contaminated hazardous contaminants shellfish neurotoxin toxins fin chemical\n",
      "3 MED-4961 69.32872009277344 not-eval\n",
      "[5.64, 4.28, 3.23, 2.98, 2.96, 2.95, 2.82, 2.73, 2.37, 2.31, 2.27, 1.96, 1.84, 1.79, 1.6, 1.49, 1.49, 1.49, 1.45, 1.44]\n",
      "fish toxin salmon toxins fin fishes salmonid toxic neurotoxic neurotoxin spawning water marine toxicant teleost mycotoxin contaminated freshwater toxicity aquatic\n",
      "4 MED-4959 68.61262512207031 not-eval\n",
      "[5.81, 4.1, 3.8, 3.41, 3.23, 2.9, 2.63, 2.32, 2.24, 2.23, 2.18, 1.99, 1.72, 1.68, 1.61, 1.59, 1.58, 1.44, 1.39, 1.19]\n",
      "fish toxin neurotoxin fishes neurotoxic fin toxins toxic teleost neurotoxicity spawning toxicant toxicity neurotoxins salmonid salmon saxitoxin zebrafish poisoning contaminated\n",
      "5 MED-4960 66.34982299804688 not-eval\n",
      "[5.77, 3.36, 3.33, 3.09, 2.61, 2.24, 2.16, 2.15, 2.11, 2.1, 2.06, 1.96, 1.84, 1.72, 1.68, 1.5, 1.46, 1.34, 1.31, 1.28]\n",
      "fish fishes toxin fin seafood marine neurotoxic spawning salmon toxic teleost salmonid shellfish neurotoxin toxins waterborne poisoning neurotoxicity zebrafish contaminated\n",
      "6 MED-4966 66.28984832763672 2\n",
      "[5.33, 3.06, 2.97, 2.51, 2.5, 2.5, 2.28, 2.1, 1.94, 1.93, 1.91, 1.81, 1.67, 1.57, 1.51, 1.49, 1.42, 1.4, 1.37, 1.32]\n",
      "fish toxin fishes neurotoxic fin toxic toxins marine neurotoxin contaminant contaminated toxicant spawning neurotoxicity teleost waterborne toxicity poisoning shellfish hazardous\n",
      "7 MED-1274 63.15934753417969 not-eval\n",
      "[4.54, 4.2, 4.04, 3.95, 3.29, 3.24, 2.98, 2.94, 2.17, 2.1, 2.01, 1.87, 1.84, 1.8, 1.58, 1.48, 1.34, 1.28, 1.19, 1.15]\n",
      "fish neurotoxin toxin fin toxins neurotoxic fishes toxic neurotoxicity mycotoxin marine neurotoxins toxicity toxicant salmon contaminant saxitoxin zebrafish shellfish teleost\n",
      "8 MED-1570 62.97511672973633 1\n",
      "[4.58, 4.37, 3.69, 3.13, 3.03, 2.8, 2.6, 2.44, 2.21, 2.08, 1.95, 1.93, 1.67, 1.67, 1.53, 1.46, 1.12, 1.11, 1.08, 1.04]\n",
      "fish toxin toxins toxic neurotoxin neurotoxic fin fishes toxicant seafood toxicity mycotoxin shellfish neurotoxicity saxitoxin marine contaminated poisoning neurotoxins contaminant\n",
      "9 MED-4934 60.92138671875 not-eval\n",
      "[5.47, 3.3, 3.17, 2.66, 2.46, 2.44, 1.89, 1.87, 1.73, 1.71, 1.65, 1.63, 1.62, 1.48, 1.46, 1.45, 1.41, 1.39, 1.32, 1.3]\n",
      "fish contaminant fishes contaminants fin toxicant chemicals teleost toxic contaminated aquatic contamination toxicants spawning salmonid neurotoxic zebrafish salmon freshwater pollutant\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-1572 7.533722877502441 1\n",
      "[5.28, 2.25]\n",
      "fish toxin\n",
      "1 MED-4961 7.4135565757751465 not-eval\n",
      "[5.73, 1.67]\n",
      "fish toxin\n",
      "2 MED-5099 7.2167863845825195 not-eval\n",
      "[7.06, 0.18]\n",
      "fish neurotransmitter\n",
      "3 MED-5098 7.214046001434326 not-eval\n",
      "[7.21]\n",
      "fish\n",
      "4 MED-5100 7.190975666046143 not-eval\n",
      "[7.18]\n",
      "fish\n",
      "5 MED-4736 7.174872398376465 not-eval\n",
      "[7.27]\n",
      "fish\n",
      "6 MED-3012 7.082894325256348 not-eval\n",
      "[7.0, 0.13]\n",
      "fish neurotransmitter\n",
      "7 MED-4959 6.904348850250244 not-eval\n",
      "[5.58, 1.28, 0.3]\n",
      "fish toxin neurotransmitter\n",
      "8 MED-3029 6.808091640472412 not-eval\n",
      "[6.82]\n",
      "fish\n",
      "9 MED-2907 6.808091640472412 not-eval\n",
      "[6.82]\n",
      "fish\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4961 17.157421112060547 not-eval\n",
      "[6.87, 5.73, 2.06, 0.57, 0.49, 0.42, 0.38, 0.33, 0.3]\n",
      "fish toxin trout enterotoxin dogfish nicking wine rainbow hampshire\n",
      "1 MED-4735 15.169953346252441 not-eval\n",
      "[7.89, 2.38, 1.83, 1.18, 0.72, 0.56, 0.55]\n",
      "fish trout aroma wine algae rainbow dogfish\n",
      "2 MED-1572 15.060108184814453 1\n",
      "[7.21, 3.64, 1.99, 1.05, 0.45, 0.34, 0.18, 0.14]\n",
      "fish toxin trout algae enterotoxin dogfish tetracycline mycobacterium\n",
      "3 MED-4360 14.987115859985352 not-eval\n",
      "[5.27, 4.54, 2.84, 2.34]\n",
      "toxin fish sexually transmitted\n",
      "4 MED-5098 14.025197982788086 not-eval\n",
      "[7.77, 2.45, 1.91, 0.94, 0.6, 0.5, 0.12]\n",
      "fish trout aroma wine dogfish rainbow algae\n",
      "5 MED-5100 13.960214614868164 not-eval\n",
      "[7.79, 2.33, 1.09, 0.92, 0.77, 0.55, 0.51]\n",
      "fish trout aroma wine algae dogfish rainbow\n",
      "6 MED-2410 13.93433666229248 not-eval\n",
      "[8.06, 2.48, 0.8, 0.69, 0.65, 0.65, 0.54]\n",
      "fish trout aroma wine rainbow dogfish algae\n",
      "7 MED-3028 13.923398971557617 not-eval\n",
      "[7.89, 2.54, 0.88, 0.86, 0.84, 0.64, 0.46]\n",
      "fish trout aroma wine algae dogfish rainbow\n",
      "8 MED-4736 13.884391784667969 not-eval\n",
      "[7.71, 2.17, 1.31, 1.11, 0.45, 0.34]\n",
      "fish trout wine algae aroma dogfish\n",
      "9 MED-2406 13.792159080505371 not-eval\n",
      "[7.59, 2.1, 1.45, 1.27, 0.52, 0.43, 0.29]\n",
      "fish trout wine algae dogfish rainbow aroma\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4360 26.49691390991211 not-eval\n",
      "[3.89, 2.62, 2.59, 2.47, 2.44, 2.04, 2.03, 1.79, 1.23, 0.71, 0.66, 0.65, 0.49, 0.4, 0.36, 0.36, 0.35, 0.32, 0.21, 0.18]\n",
      "fish sexually toxin transmitted sex fishes poison transmission cause toxic genus spread, fishing habitat drug chemical him virus food\n",
      "1 MED-4966 21.171051025390625 2\n",
      "[5.13, 2.45, 2.14, 2.03, 1.59, 1.58, 1.35, 0.76, 0.68, 0.56, 0.55, 0.37, 0.33, 0.32, 0.26, 0.21, 0.19, 0.19, 0.16, 0.15]\n",
      "fish fishes poison sex sexually cause toxin transmitted habitat toxic fishing genus him, virus chemical from food is.\n",
      "2 MED-1572 19.377138137817383 1\n",
      "[5.31, 3.14, 2.35, 2.27, 1.47, 0.74, 0.65, 0.61, 0.44, 0.34, 0.33, 0.33, 0.31, 0.23, 0.21, 0.13, 0.12, 0.11]\n",
      "fish toxin fishes poison cause toxic habitat fishing genus him chemical spread, virus from are. is\n",
      "3 MED-1570 18.265485763549805 1\n",
      "[4.05, 3.38, 2.13, 1.93, 1.48, 1.12, 0.72, 0.7, 0.47, 0.36, 0.34, 0.3, 0.21, 0.2, 0.19, 0.16, 0.14, 0.13]\n",
      "fish toxin fishes poison cause toxic genus habitat fishing him chemical, virus are from is food drug\n",
      "4 MED-4959 17.838754653930664 not-eval\n",
      "[5.21, 2.65, 2.49, 1.9, 1.34, 0.63, 0.6, 0.55, 0.51, 0.38, 0.37, 0.36, 0.26, 0.21, 0.18, 0.18, 0.16, 0.16, 0.15, 0.15]\n",
      "fish toxin fishes poison cause fishing toxic genus drug habitat him chemical from, transmitted spread food gene for is\n",
      "5 MED-4968 17.31507110595703 2\n",
      "[3.32, 3.17, 1.75, 1.61, 1.53, 1.17, 1.04, 0.77, 0.64, 0.58, 0.31, 0.25, 0.21, 0.21, 0.19, 0.18, 0.16]\n",
      "fish toxin transmission fishes cause poison transmitted genus habitat spread virus, from are him toxic food\n",
      "6 MED-1569 17.281635284423828 1\n",
      "[4.62, 4.14, 2.05, 1.71, 1.11, 0.89, 0.54, 0.39, 0.34, 0.33, 0.23, 0.22, 0.21, 0.12]\n",
      "toxin fish poison fishes cause toxic, genus parker drug fishing chemical him from\n",
      "7 MED-4381 17.2426815032959 not-eval\n",
      "[4.82, 2.84, 1.62, 1.58, 1.55, 0.93, 0.52, 0.46, 0.43, 0.36, 0.3, 0.29, 0.24, 0.22, 0.2, 0.17, 0.12, 0.11, 0.1]\n",
      "fish poison toxin fishes cause toxic chemical, habitat genus drug fishing him parker virus from is for.\n",
      "8 MED-4961 17.08672523498535 not-eval\n",
      "[5.62, 2.88, 2.56, 1.46, 1.33, 0.64, 0.53, 0.52, 0.31, 0.2, 0.2, 0.18, 0.15, 0.14, 0.12, 0.11]\n",
      "fish toxin fishes cause poison fishing toxic habitat genus, from food chemical him. virus\n",
      "9 MED-4958 16.976192474365234 not-eval\n",
      "[5.5, 2.58, 1.77, 1.08, 1.06, 0.58, 0.58, 0.58, 0.56, 0.49, 0.41, 0.23, 0.22, 0.21, 0.2, 0.18, 0.17, 0.16]\n",
      "fish fishes poison toxic cause fishing drug genus toxin chemical, him habitat for are food from gene\n"
     ]
    }
   ],
   "source": [
    "observe_model = [\"adalm\", \"dapt-splade-59372\", \"dapt-59372\", \"splade\"]\n",
    "for qid in qids_dapt_worse:\n",
    "    print(\"----------------------------\")\n",
    "    print(queries[qid])\n",
    "    for model_name in observe_model:\n",
    "        print(\"-------------\")\n",
    "        print(model_name)\n",
    "        analysis(model_name, qid, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "10c27101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Stopping Heart Disease in Childhood\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3255 74.21464538574219 1\n",
      "[4.1, 3.93, 3.16, 2.32, 2.31, 2.26, 2.24, 2.09, 2.0, 1.89, 1.88, 1.81, 1.75, 1.73, 1.73, 1.63, 1.6, 1.57, 1.52, 1.46]\n",
      "childhood children early child infancy intervention boys cvd infants pediatric atherosclerosis prevention age youth paediatric coronary heart cardiovascular adolescents ecg\n",
      "1 MED-3979 63.191444396972656 not-eval\n",
      "[4.46, 4.21, 3.04, 2.76, 2.46, 2.42, 2.36, 2.21, 2.21, 2.2, 1.95, 1.94, 1.85, 1.53, 1.43, 1.36, 1.35, 1.35, 1.33, 1.33]\n",
      "childhood children child age infancy wheezing school paediatric early pediatric birth infants disease young adolescence year period pediatrics kindergarten youth\n",
      "2 MED-3954 61.03766632080078 not-eval\n",
      "[4.91, 4.41, 3.44, 2.79, 2.39, 2.35, 2.35, 2.33, 1.94, 1.93, 1.89, 1.86, 1.85, 1.79, 1.68, 1.57, 1.41, 1.35, 1.27, 1.23]\n",
      "childhood heart children ihd cvd child cardiac disease boys ecg chd cardiovascular age early coronary bradycardia hr youth hearts atherosclerosis\n",
      "3 MED-3253 60.666969299316406 2\n",
      "[3.9, 3.0, 2.97, 2.83, 2.67, 2.39, 2.39, 2.38, 2.27, 2.05, 2.04, 1.96, 1.93, 1.88, 1.74, 1.73, 1.7, 1.42, 1.21, 1.18]\n",
      "heart early youth children childhood age disease atherosclerosis coronary chd young cvd adolescence adolescents pediatric cardiovascular cardiac risk school ecg\n",
      "4 MED-5018 59.76390075683594 not-eval\n",
      "[3.41, 3.29, 2.43, 2.36, 2.35, 2.24, 2.2, 2.14, 2.06, 2.02, 1.8, 1.8, 1.68, 1.61, 1.55, 1.52, 1.32, 1.26, 1.08, 1.04]\n",
      "children early childhood prevention wheezing age infants disease intervention infancy pediatrics pediatric birth child infant preventive period preventing development asthma\n",
      "5 MED-3976 59.71277618408203 not-eval\n",
      "[4.24, 4.02, 3.04, 2.52, 2.41, 2.37, 2.11, 2.08, 1.97, 1.82, 1.77, 1.68, 1.62, 1.6, 1.59, 1.48, 1.45, 1.44, 1.39, 1.39]\n",
      "children childhood child early age wheezing paediatric pediatric young preschool disease infants year birth infancy period pediatrics kindergarten school years\n",
      "6 MED-3425 59.491539001464844 not-eval\n",
      "[4.93, 4.0, 2.96, 2.87, 2.86, 2.75, 2.28, 2.1, 2.02, 1.82, 1.78, 1.68, 1.57, 1.55, 1.5, 1.28, 1.25, 1.22, 1.22, 1.18]\n",
      "heart chd cardiac cvd disease age coronary early cardiovascular ecg ihd bradycardia young hearts hf risk years later childhood hr\n",
      "7 MED-1190 58.029319763183594 not-eval\n",
      "[4.06, 3.96, 3.65, 3.26, 2.39, 2.36, 2.24, 2.02, 1.99, 1.93, 1.79, 1.78, 1.75, 1.52, 1.51, 1.49, 1.44, 1.43, 1.33, 1.32]\n",
      "heart children chd childhood cvd age child cardiac coronary youth pediatric paediatric disease school boys cardiovascular young ihd hr atherosclerosis\n",
      "8 MED-1954 57.711936950683594 not-eval\n",
      "[3.93, 3.32, 2.73, 2.69, 2.68, 2.57, 2.56, 2.54, 2.43, 1.95, 1.85, 1.76, 1.69, 1.48, 1.46, 1.32, 1.21, 1.21, 1.15, 1.05]\n",
      "children childhood child infancy birth early preschool age infants preterm premature paediatric infant young school kindergarten later boys pediatric adolescents\n",
      "9 MED-2054 55.00902557373047 not-eval\n",
      "[4.34, 3.71, 3.1, 2.5, 2.28, 2.23, 2.17, 2.12, 2.0, 1.92, 1.81, 1.79, 1.75, 1.66, 1.38, 1.34, 1.29, 1.21, 1.2, 1.15]\n",
      "children childhood child pediatric paediatric age infants early infancy preschool pediatrics young toddlers boys infant kindergarten year birth disease years\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3954 11.270530700683594 not-eval\n",
      "[3.9, 2.99, 2.9, 1.82]\n",
      "heart childhood children disease\n",
      "1 MED-1548 8.852556228637695 not-eval\n",
      "[4.67, 2.42, 2.31]\n",
      "heart disease children\n",
      "2 MED-4919 7.52935791015625 not-eval\n",
      "[3.17, 2.55, 2.08]\n",
      "children disease childhood\n",
      "3 MED-2590 7.197972774505615 not-eval\n",
      "[4.46, 2.54, 0.2]\n",
      "heart disease myocardium\n",
      "4 MED-1366 6.953921318054199 not-eval\n",
      "[3.65, 1.86, 1.45]\n",
      "heart disease children\n",
      "5 MED-1996 6.712478160858154 not-eval\n",
      "[3.38, 2.07, 1.26]\n",
      "children childhood disease\n",
      "6 MED-2484 6.663737773895264 not-eval\n",
      "[2.88, 2.54, 1.25]\n",
      "children childhood disease\n",
      "7 MED-2474 6.662322044372559 not-eval\n",
      "[2.97, 2.78, 1.8]\n",
      "children childhood disease\n",
      "8 MED-1722 6.632974147796631 not-eval\n",
      "[3.18, 2.06, 1.73]\n",
      "children childhood disease\n",
      "9 MED-2479 6.4849653244018555 not-eval\n",
      "[2.77, 1.62, 1.01]\n",
      "children disease childhood\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3954 20.00507354736328 not-eval\n",
      "[5.93, 4.76, 4.33, 3.58, 0.65, 0.46, 0.39, 0.19]\n",
      "heart disease childhood children ischaemic abdominal repeated fever\n",
      "1 MED-2590 18.260112762451172 not-eval\n",
      "[5.89, 5.15, 2.31, 1.6, 1.27, 1.0, 0.64, 0.35]\n",
      "heart disease children myocardial cardiovascular coronary repeated remission\n",
      "2 MED-1548 16.954599380493164 not-eval\n",
      "[5.99, 4.13, 3.74, 3.4, 0.74, 0.35]\n",
      "heart disease children cardiovascular repeated ventilation\n",
      "3 MED-1680 16.1179141998291 not-eval\n",
      "[4.13, 3.44, 2.51, 2.31, 2.25, 0.73, 0.61, 0.41]\n",
      "disease heart children myocardial cardiovascular coronary abdominal repeated\n",
      "4 MED-1213 16.079662322998047 not-eval\n",
      "[5.58, 4.04, 3.47, 2.1, 0.89, 0.48, 0.17]\n",
      "heart disease cardiovascular children repeated ventilation abdominal\n",
      "5 MED-4496 14.69064712524414 not-eval\n",
      "[5.78, 4.82, 2.03, 1.21, 1.09, 0.18]\n",
      "heart disease cardiovascular myocardial coronary fever\n",
      "6 MED-3425 14.483330726623535 not-eval\n",
      "[5.99, 4.85, 1.59, 0.95, 0.78, 0.45]\n",
      "heart disease children cardiovascular coronary repeated\n",
      "7 MED-4255 14.271587371826172 not-eval\n",
      "[5.41, 5.2, 1.06, 0.96, 0.71, 0.54, 0.27, 0.11]\n",
      "heart disease coronary children cardiovascular repeated myocardial fever\n",
      "8 MED-4613 14.271587371826172 not-eval\n",
      "[5.41, 5.2, 1.06, 0.96, 0.71, 0.54, 0.27, 0.11]\n",
      "heart disease coronary children cardiovascular repeated myocardial fever\n",
      "9 MED-1409 14.21241569519043 not-eval\n",
      "[5.86, 5.05, 2.44, 1.02, 0.62]\n",
      "heart disease cardiovascular coronary myocardial\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3954 16.621994018554688 not-eval\n",
      "[4.8, 3.35, 2.95, 2.52, 1.07, 0.66, 0.64, 0.5, 0.11]\n",
      "childhood heart disease child teen cause hearts diseases pre\n",
      "1 MED-4247 14.987343788146973 not-eval\n",
      "[4.87, 3.4, 2.08, 1.34, 1.23, 0.59, 0.38, 0.3, 0.25, 0.2, 0.16, 0.11]\n",
      "heart disease stop hearts stopping stopped cause diseases drug goal treatment hospital\n",
      "2 MED-4616 14.987343788146973 not-eval\n",
      "[4.87, 3.4, 2.08, 1.34, 1.23, 0.59, 0.38, 0.3, 0.25, 0.2, 0.16, 0.11]\n",
      "heart disease stop hearts stopping stopped cause diseases drug goal treatment hospital\n",
      "3 MED-3253 14.770957946777344 2\n",
      "[3.27, 3.2, 2.57, 2.09, 1.03, 0.63, 0.57, 0.49, 0.34, 0.25, 0.16]\n",
      "heart childhood disease child teen hearts cause prevent diseases youth when\n",
      "4 MED-1996 14.34057903289795 not-eval\n",
      "[4.23, 2.7, 2.6, 1.49, 1.49, 0.76, 0.48, 0.18, 0.12]\n",
      "childhood disease child heart teen cause diseases youth pre\n",
      "5 MED-1394 14.288932800292969 not-eval\n",
      "[4.72, 3.0, 1.98, 1.27, 0.51, 0.4, 0.29, 0.27, 0.19, 0.15, 0.14]\n",
      "heart disease stop stopped prevent diseases for cause treatment drug goal\n",
      "6 MED-1994 13.813417434692383 not-eval\n",
      "[3.53, 2.79, 2.44, 1.35, 0.73, 0.66, 0.56, 0.48, 0.44, 0.43, 0.27]\n",
      "childhood disease child teen heart cause diseases prevent stop pre youth\n",
      "7 MED-2590 13.732902526855469 not-eval\n",
      "[5.41, 4.41, 1.61, 0.71, 0.65, 0.29, 0.21, 0.14, 0.11, 0.11]\n",
      "heart disease hearts diseases treatment goal cure drug cause for\n",
      "8 MED-1949 13.273659706115723 not-eval\n",
      "[3.27, 3.24, 2.62, 1.35, 0.58, 0.49, 0.44, 0.36, 0.24, 0.15, 0.13]\n",
      "disease heart child childhood cause diseases pre teen prevent when treatment\n",
      "9 MED-5301 13.26492977142334 not-eval\n",
      "[4.69, 3.42, 1.09, 0.62, 0.46, 0.45, 0.44, 0.34, 0.32, 0.27, 0.25, 0.15, 0.14, 0.12]\n",
      "heart disease hearts stop diseases treatment goal for drug cause prevent cure doing hospital\n",
      "----------------------------\n",
      "sulfur\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-1418 49.92276382446289 1\n",
      "[5.16, 4.6, 3.48, 2.72, 2.4, 2.05, 1.95, 1.86, 1.74, 1.74, 1.6, 1.55, 1.45, 1.33, 1.18, 1.14, 1.04, 0.91, 0.89, 0.88]\n",
      "sulfur sulfide h2s thiosulfate sulfite s sulphur thioether gas se disulfide sulfation sulphide bisulfite sulfate cysteine thiolate ms sulfa hs\n",
      "1 MED-1185 47.17229461669922 1\n",
      "[4.88, 4.42, 3.4, 3.13, 1.93, 1.92, 1.74, 1.46, 1.37, 1.32, 1.29, 1.28, 1.23, 1.13, 1.08, 1.07, 1.07, 1.01, 0.91, 0.72]\n",
      "sulfur sulfite sulfide thiosulfate so2 h2s bisulfite sulfonate ssi sulphur se selenium sulfa sulfate s sr sulfation disulfide gas sulphide\n",
      "2 MED-1421 43.50474548339844 1\n",
      "[4.9, 4.51, 3.46, 2.49, 2.33, 1.82, 1.62, 1.54, 1.52, 1.47, 1.39, 1.35, 1.32, 1.25, 1.16, 1.05, 0.95, 0.91, 0.81, 0.76]\n",
      "sulfur sulfide h2s thiosulfate sulfite gas thioether sulphur sulfation sulfate cysteine sulfa sulphide se disulfide ssi bisulfite volatile so2 thiolate\n",
      "3 MED-1184 42.00126647949219 1\n",
      "[4.68, 4.36, 3.39, 2.46, 2.33, 1.68, 1.53, 1.48, 1.41, 1.32, 1.3, 1.23, 1.14, 1.11, 1.1, 1.04, 1.02, 0.95, 0.85, 0.84]\n",
      "sulfur sulfide h2s thiosulfate sulfite se gas bisulfite sulfation thioether sulphide sulfate disulfide sulphur cysteine sulfa s ms selenium sb\n",
      "4 MED-4499 36.92291259765625 not-eval\n",
      "[4.85, 3.46, 1.9, 1.84, 1.53, 1.51, 1.45, 1.42, 1.41, 1.2, 1.15, 1.14, 1.09, 1.08, 1.05, 0.88, 0.84, 0.84, 0.75, 0.65]\n",
      "sulfur sulfide garlic h2s selenium sulphur volatile sulfite disulfide cysteine sulfa thiosulfate sulfation thioether se gas sulphide ms bisulfite thiolate\n",
      "5 MED-895 36.323734283447266 not-eval\n",
      "[5.01, 4.17, 2.46, 2.07, 1.95, 1.71, 1.69, 1.62, 1.46, 1.34, 1.18, 1.08, 1.05, 0.91, 0.87, 0.85, 0.83, 0.76, 0.67, 0.54]\n",
      "sulfur sulphur h2s sulfide sulfite gas volatile so2 thiosulfate bisulfite s sulphide se cysteine sr thioether elemental selenium ms silicon\n",
      "6 MED-3282 31.667724609375 not-eval\n",
      "[5.49, 2.95, 2.89, 2.45, 2.38, 2.02, 1.81, 1.65, 1.58, 1.52, 1.03, 0.95, 0.93, 0.81, 0.7, 0.68, 0.61, 0.56, 0.46, 0.45]\n",
      "sulfur sulfide sulphur h2s gas methionine thioether volatile ms cysteine elemental s sulfation disulfide sulphide sulfa nitrogen thiolate thiosulfate glutathione\n",
      "7 MED-723 30.296676635742188 1\n",
      "[4.13, 4.01, 3.28, 2.58, 1.52, 1.2, 1.15, 0.96, 0.91, 0.84, 0.76, 0.71, 0.7, 0.45, 0.41, 0.4, 0.39, 0.37, 0.36, 0.36]\n",
      "sulfide sulfur h2s gas thiosulfate sulphide volatile sulfite so2 disulfide skin se ms si sulfate sinus thioether oxygen carbon nitrogen\n",
      "8 MED-2065 29.71990203857422 not-eval\n",
      "[3.25, 1.86, 1.75, 1.53, 1.51, 1.5, 1.31, 1.2, 1.13, 1.11, 0.98, 0.97, 0.97, 0.9, 0.83, 0.77, 0.76, 0.72, 0.67, 0.66]\n",
      "sulfur sulfation sulfide thioether sf sulfa s se glutathione sulfonate sr ms sb si ssi su sulfate sns sulfo garlic\n",
      "9 MED-4457 27.085725784301758 not-eval\n",
      "[3.41, 2.65, 1.63, 1.53, 1.29, 1.12, 1.08, 1.05, 1.01, 1.0, 0.99, 0.97, 0.95, 0.9, 0.74, 0.62, 0.58, 0.58, 0.56, 0.53]\n",
      "sulfur sf sr sulfation sulfa se s sulfide sb ssi sulfonate thioether si glutathione su sulfo ms sns oxygen scleroderma\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3282 8.562302589416504 not-eval\n",
      "[8.28, 0.89, 0.1]\n",
      "sulfurfide sulphur\n",
      "1 MED-4499 6.604548454284668 not-eval\n",
      "[5.18, 0.66]\n",
      "sulfurfide\n",
      "2 MED-1185 6.482168197631836 1\n",
      "[7.0, 0.74]\n",
      "sulfurfide\n",
      "3 MED-1421 5.7656683921813965 1\n",
      "[3.77, 1.93]\n",
      "sulfurfide\n",
      "4 MED-4320 5.310262203216553 not-eval\n",
      "[5.09]\n",
      "sulfur\n",
      "5 MED-895 4.9981560707092285 not-eval\n",
      "[4.71, 0.29]\n",
      "sulfur sulphur\n",
      "6 MED-3228 4.686855316162109 not-eval\n",
      "[4.68]\n",
      "sulfur\n",
      "7 MED-1953 4.511181831359863 not-eval\n",
      "[4.49]\n",
      "sulfur\n",
      "8 MED-1420 4.090086936950684 1\n",
      "[3.33, 0.68]\n",
      "sulfurfide\n",
      "9 MED-4206 3.4403128623962402 not-eval\n",
      "[3.37]\n",
      "sulfur\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3282 8.17801284790039 not-eval\n",
      "[6.09, 1.08, 0.87, 0.3, 0.19]\n",
      "sulfur nitrogen methyl metals hydrogen\n",
      "1 MED-4320 5.788112640380859 not-eval\n",
      "[4.18, 0.99, 0.84]\n",
      "sulfur metals methyl\n",
      "2 MED-4499 5.05279541015625 not-eval\n",
      "[3.84, 1.16]\n",
      "sulfur methyl\n",
      "3 MED-4472 4.419121265411377 not-eval\n",
      "[2.26, 2.09, 0.21]\n",
      "nitrogen methyl metals\n",
      "4 MED-4057 3.5758795738220215 not-eval\n",
      "[2.07, 1.39]\n",
      "methyl nitrogen\n",
      "5 MED-1605 3.5501327514648438 not-eval\n",
      "[2.05, 1.5]\n",
      "methyl nitrogen\n",
      "6 MED-4451 3.4873290061950684 not-eval\n",
      "[1.94, 1.0, 0.57]\n",
      "methyl nitrogen metals\n",
      "7 MED-5099 3.4808621406555176 not-eval\n",
      "[2.73, 0.8]\n",
      "methyl metals\n",
      "8 MED-4483 3.4526612758636475 not-eval\n",
      "[1.96, 1.39]\n",
      "methyl nitrogen\n",
      "9 MED-4622 3.359630823135376 not-eval\n",
      "[2.87, 0.39]\n",
      "methyl nitrogen\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-1185 14.310565948486328 1\n",
      "[6.49, 5.74, 0.54, 0.54, 0.21, 0.18, 0.17, 0.12, 0.11]\n",
      "sul sulfur chemical genus is for habitat are from\n",
      "1 MED-2065 13.716564178466797 not-eval\n",
      "[6.32, 3.27, 1.83, 0.82, 0.65, 0.5, 0.22, 0.15, 0.15]\n",
      "sul sulfur but genus chemical is for from are\n",
      "2 MED-1421 13.20486831665039 1\n",
      "[5.38, 5.37, 0.52, 0.52, 0.43, 0.25, 0.14]\n",
      "sul sulfur chemical genus from is habitat\n",
      "3 MED-3282 13.172309875488281 not-eval\n",
      "[7.11, 4.44, 1.0, 0.43, 0.24, 0.11]\n",
      "sulfur sul chemical genus from that\n",
      "4 MED-2067 12.116754531860352 not-eval\n",
      "[6.2, 3.51, 0.7, 0.64, 0.34, 0.25, 0.14]\n",
      "sul sulfur genus chemical is for habitat\n",
      "5 MED-1418 11.928779602050781 1\n",
      "[5.24, 3.67, 1.07, 0.67, 0.51, 0.24, 0.2, 0.14]\n",
      "sul sulfur but chemical genus from is habitat\n",
      "6 MED-1184 11.925649642944336 1\n",
      "[5.46, 3.36, 1.58, 0.6, 0.38, 0.25, 0.15, 0.11]\n",
      "sul sulfur but chemical genus from for that\n",
      "7 MED-4320 11.866487503051758 not-eval\n",
      "[6.09, 3.83, 0.39, 0.37, 0.33, 0.16, 0.15]\n",
      "sulfur sul from chemical genus for habitat\n",
      "8 MED-5127 11.75358772277832 not-eval\n",
      "[6.21, 2.98, 0.52, 0.47, 0.39, 0.25, 0.2, 0.18]\n",
      "sul sulfur genus is chemical 31 for from\n",
      "9 MED-4457 10.987569808959961 not-eval\n",
      "[5.74, 2.86, 0.58, 0.45, 0.29, 0.25, 0.16]\n",
      "sul sulfur genus chemical from is for\n",
      "----------------------------\n",
      "Chronic Headaches and Pork Tapeworms\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3175 183.0554962158203 2\n",
      "[5.36, 4.68, 4.64, 4.5, 4.38, 4.37, 4.12, 4.06, 3.58, 3.5, 3.48, 3.36, 3.17, 3.14, 2.91, 2.89, 2.74, 2.73, 2.6, 2.44]\n",
      "porkworm headache tape cestode taenia cysticerc cysticercosis swine headaches helminth porcine parasite pig migraine pigs trematode soli worms worm\n",
      "1 MED-3171 135.55697631835938 2\n",
      "[6.74, 4.73, 3.94, 3.92, 3.84, 3.83, 3.69, 3.5, 3.32, 3.21, 3.12, 3.06, 2.99, 2.5, 2.38, 2.29, 2.2, 2.2, 2.08, 2.05]\n",
      "pork cysticerc swine pig cestode porcine cysticercosis taenia pigs boar parasite helminth meat nematode boars animal trichinella parasites ham nematodes\n",
      "2 MED-5094 122.07426452636719 not-eval\n",
      "[5.54, 5.49, 5.07, 3.5, 3.19, 3.07, 3.02, 2.93, 2.88, 2.77, 2.74, 2.34, 2.03, 2.0, 2.0, 1.86, 1.83, 1.77, 1.74, 1.74]\n",
      "##worm tape cestode helminth trematode worms taenia parasite worm cysticerc twa nematode helminths echinococcus parasites cercariae sag infection trichuris cysticercosis\n",
      "3 MED-4672 107.47332763671875 1\n",
      "[4.51, 4.32, 4.09, 4.06, 3.83, 3.47, 3.42, 2.72, 2.49, 2.37, 2.34, 2.34, 2.27, 2.15, 2.11, 2.07, 2.02, 1.82, 1.77, 1.69]\n",
      "cysticercosis cysticerc cestode taenia tape helminthworm soli trichinella trematode echinococcus t parasite toxocara twa trichuris helminths sag nematode cns\n",
      "4 MED-3169 102.92080688476562 2\n",
      "[6.38, 5.6, 4.39, 4.22, 4.03, 3.47, 2.84, 2.68, 2.66, 2.38, 2.32, 2.04, 1.99, 1.98, 1.9, 1.7, 1.69, 1.47, 1.45, 1.39]\n",
      "headache headaches cysticerc migraine cysticercosis helminth taenia cestode pain parasite cns trematode brain nematode infection si helminths ct parasitic parasites\n",
      "5 MED-3288 98.27809143066406 1\n",
      "[6.39, 4.66, 4.33, 4.02, 3.68, 3.06, 2.58, 2.42, 2.38, 2.29, 2.23, 2.14, 1.91, 1.9, 1.9, 1.57, 1.53, 1.5, 1.42, 1.41]\n",
      "pork porcine swine pig pigs boar pain chronic animal boars prr meat brain sui symptoms slaughter ham carcass cns neurotoxic\n",
      "6 MED-3177 97.34379577636719 2\n",
      "[4.67, 4.18, 3.68, 3.14, 3.1, 2.87, 2.85, 2.66, 2.16, 2.03, 1.98, 1.88, 1.87, 1.74, 1.67, 1.62, 1.58, 1.45, 1.44, 1.44]\n",
      "cysticerc cysticercosis taenia parasite helminth cestode cns headache nematode trematode parasites infection brain echinococcus toxocara si migraine parasitic ct nematodes\n",
      "7 MED-3302 96.31380462646484 1\n",
      "[5.27, 4.7, 4.43, 4.15, 3.93, 3.26, 2.65, 2.41, 2.32, 2.17, 1.93, 1.85, 1.83, 1.8, 1.79, 1.75, 1.68, 1.66, 1.58, 1.42]\n",
      "swine porcine pork pig pigs boar boars animal brain sui slaughter abattoir cns ip prr pain si neurotoxic animals neurotoxicity\n",
      "8 MED-3319 89.58319854736328 not-eval\n",
      "[5.9, 4.44, 4.02, 3.85, 3.66, 2.73, 2.42, 2.34, 2.31, 2.08, 2.04, 2.0, 1.89, 1.83, 1.68, 1.66, 1.44, 1.39, 1.29, 1.26]\n",
      "pork porcine swine pig pigs boar brain animal boars slaughter meat cns abattoir carcass pain neurotoxic neurotoxicity animals farm paralysis\n",
      "9 MED-3316 87.91371154785156 1\n",
      "[4.83, 4.81, 4.13, 3.92, 3.86, 3.03, 2.46, 2.35, 2.19, 2.11, 2.04, 1.88, 1.55, 1.5, 1.5, 1.42, 1.42, 1.32, 1.31, 1.28]\n",
      "porcine swine pig pork pigs boar animal brain boars prr cns sui neurotoxic pain symptoms abattoir animals piglets rodent neurotoxicity\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3175 12.908623695373535 2\n",
      "[4.92, 4.06, 3.82, 0.1]\n",
      "tapeworm migraine pork drugs\n",
      "1 MED-3661 7.7428412437438965 not-eval\n",
      "[7.37, 0.35]\n",
      "migraine drugs\n",
      "2 MED-3663 7.511664390563965 not-eval\n",
      "[6.72, 0.62, 0.35]\n",
      "migraine chronic drugs\n",
      "3 MED-3664 7.02272367477417 not-eval\n",
      "[6.51, 0.23]\n",
      "migraine drugs\n",
      "4 MED-3658 6.997478008270264 not-eval\n",
      "[6.65, 0.33]\n",
      "migraine drugs\n",
      "5 MED-3515 6.990927219390869 not-eval\n",
      "[6.07, 0.87]\n",
      "migraine headaches\n",
      "6 MED-3169 6.68427038192749 2\n",
      "[6.32, 0.39]\n",
      "migraine headaches\n",
      "7 MED-3660 6.624794960021973 not-eval\n",
      "[6.51, 0.23, 0.2]\n",
      "migraine headaches drugs\n",
      "8 MED-5094 6.620660781860352 not-eval\n",
      "[6.62]\n",
      "tapeworm\n",
      "9 MED-4126 6.513625144958496 not-eval\n",
      "[6.49]\n",
      "migraine\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4818 15.958596229553223 not-eval\n",
      "[8.02, 2.41, 1.06, 0.9, 0.9, 0.84, 0.52, 0.46, 0.43, 0.25, 0.17]\n",
      "pork swine arousal agitation food recruiting aroma chicks fever nonfermented fruits\n",
      "1 MED-3175 15.163849830627441 2\n",
      "[7.1, 4.11, 1.33, 1.19, 0.45, 0.34, 0.26, 0.2, 0.13]\n",
      "pork tapeworm swine fever perfringens armyworm aroma menstruation agitation\n",
      "2 MED-1610 14.639447212219238 not-eval\n",
      "[7.35, 2.04, 1.73, 1.45, 0.7, 0.41, 0.41, 0.26, 0.23]\n",
      "pork arousal swine food aroma fruits chicks agitation refed\n",
      "3 MED-2340 13.896597862243652 not-eval\n",
      "[7.03, 2.24, 2.12, 1.28, 0.6, 0.55, 0.26, 0.14, 0.12]\n",
      "pork swine allergic agitation aroma goats perfringens fever arousal\n",
      "4 MED-3288 12.979414939880371 1\n",
      "[7.77, 2.27, 1.96, 0.97, 0.89, 0.86, 0.74, 0.36]\n",
      "pork swine arousal fever chronic agitation food aroma\n",
      "5 MED-2341 12.779240608215332 not-eval\n",
      "[7.2, 2.1, 2.07, 0.71, 0.61, 0.6, 0.54, 0.31, 0.14]\n",
      "pork swine allergic food fever goats perfringens aroma diarrhea\n",
      "6 MED-1979 12.29068374633789 not-eval\n",
      "[7.37, 1.87, 0.81, 0.73, 0.54, 0.3, 0.28, 0.22, 0.15]\n",
      "pork swine aroma agitation fever food chicks turkeys perfringens\n",
      "7 MED-3171 12.130341529846191 2\n",
      "[7.97, 2.06, 1.12, 0.37, 0.26, 0.24, 0.1]\n",
      "pork swine agitation chicks perfringens food aroma\n",
      "8 MED-1977 12.104321479797363 not-eval\n",
      "[6.66, 2.89, 1.05, 0.85, 0.63, 0.37, 0.3]\n",
      "pork swine arousal fever aroma perfringens agitation\n",
      "9 MED-3653 11.90197467803955 not-eval\n",
      "[7.06, 1.71, 0.91, 0.49, 0.44, 0.41, 0.34, 0.25, 0.17, 0.11]\n",
      "pork swine food arousal fever perfringens chicks turkeys aroma menstruation\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3175 25.859359741210938 2\n",
      "[5.5, 4.51, 3.56, 2.74, 2.56, 2.36, 1.78, 1.67, 0.34, 0.31, 0.24, 0.23]\n",
      "pork headache tapeworm worm chang pig cause habitat,. bug\n",
      "1 MED-3288 13.77364730834961 1\n",
      "[5.12, 2.42, 1.64, 1.47, 0.67, 0.48, 0.46, 0.33, 0.27, 0.25, 0.2]\n",
      "pork chronic cause pig pain., habitat worm food him\n",
      "2 MED-3515 12.524946212768555 not-eval\n",
      "[5.25, 2.56, 2.02, 1.08, 0.58, 0.32, 0.27, 0.21, 0.16]\n",
      "headache chang chronic cause, pains for.\n",
      "3 MED-4814 12.343881607055664 not-eval\n",
      "[4.44, 3.07, 2.54, 1.36, 0.44, 0.29, 0.19]\n",
      "pork chronic pig cause food habitat,\n",
      "4 MED-3517 12.091144561767578 not-eval\n",
      "[4.82, 2.43, 2.28, 0.99, 0.69, 0.61, 0.2, 0.2, 0.19]\n",
      "headache chang chronic cause pain,. him for\n",
      "5 MED-5094 11.480010032653809 not-eval\n",
      "[3.82, 2.75, 2.54, 0.76, 0.53, 0.42, 0.22, 0.19, 0.15]\n",
      "tapeworm worm cause habitat, food bugs\n",
      "6 MED-3169 11.41678237915039 2\n",
      "[5.52, 2.76, 1.57, 0.59, 0.31, 0.29]\n",
      "headache chang cause, pains\n",
      "7 MED-3171 10.886579513549805 2\n",
      "[5.36, 1.63, 1.27, 0.64, 0.58, 0.48, 0.37, 0.24, 0.15, 0.1]\n",
      "pork pig wormworm cause habitat food, for bug\n",
      "8 MED-4357 10.751043319702148 not-eval\n",
      "[5.05, 1.61, 1.45, 0.47, 0.42, 0.39, 0.37, 0.33, 0.21, 0.18, 0.16]\n",
      "pork pig worm foodworm habitat, cause bug for him\n",
      "9 MED-4818 10.72802448272705 not-eval\n",
      "[5.82, 1.82, 1.7, 0.53, 0.47, 0.24]\n",
      "pork pig cause worm food,\n",
      "----------------------------\n",
      "Heart Disease Starts in Childhood\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3253 80.20654296875 2\n",
      "[4.01, 3.36, 3.22, 3.19, 2.82, 2.77, 2.76, 2.62, 2.57, 2.51, 2.21, 2.19, 2.09, 2.0, 1.99, 1.97, 1.86, 1.83, 1.57, 1.47]\n",
      "heart early youth atherosclerosis children childhood age disease young coronary risk adolescents chd cardiovascular cvd adolescence pediatric cardiac onset earlier\n",
      "1 MED-3255 76.70067596435547 2\n",
      "[4.25, 3.91, 3.54, 2.66, 2.51, 2.43, 2.3, 2.13, 2.12, 2.03, 2.02, 1.88, 1.87, 1.83, 1.82, 1.8, 1.77, 1.64, 1.62, 1.53]\n",
      "childhood children early infancy atherosclerosis child boys infants cvd pediatric age youth paediatric young cardiovascular coronary adolescents heart years ecg\n",
      "2 MED-3979 75.74188232421875 not-eval\n",
      "[4.62, 4.19, 3.19, 3.18, 2.84, 2.48, 2.38, 2.35, 2.21, 2.21, 2.08, 2.07, 2.03, 1.92, 1.77, 1.75, 1.55, 1.55, 1.47, 1.46]\n",
      "childhood children age child infancy early paediatric pediatric birth wheezing years infants disease young school onset period year preschool adolescence\n",
      "3 MED-1954 71.91215515136719 not-eval\n",
      "[3.91, 3.45, 3.18, 3.1, 3.04, 2.94, 2.89, 2.86, 2.58, 1.94, 1.9, 1.86, 1.81, 1.59, 1.55, 1.51, 1.48, 1.4, 1.25, 1.24]\n",
      "children childhood preschool infancy birth age early child infants infant paediatric young preterm later years premature risk born toddlers boys\n",
      "4 MED-4745 70.36538696289062 not-eval\n",
      "[4.83, 3.35, 3.35, 3.08, 2.33, 2.2, 2.19, 2.12, 2.05, 1.98, 1.96, 1.87, 1.79, 1.76, 1.74, 1.71, 1.69, 1.67, 1.45, 1.32]\n",
      "childhood early children age child onset young timing adolescence years development boys earlier later developmental infancy preschool period adolescents puberty\n",
      "5 MED-3976 69.91120910644531 not-eval\n",
      "[4.21, 4.17, 3.19, 2.82, 2.79, 2.48, 2.28, 2.26, 2.25, 2.24, 2.17, 1.94, 1.85, 1.84, 1.82, 1.79, 1.71, 1.53, 1.5, 1.48]\n",
      "children childhood child early age young paediatric preschool years pediatric wheezing disease year infancy birth infants period lung life toddlers\n",
      "6 MED-3425 68.95074462890625 not-eval\n",
      "[5.07, 4.07, 3.19, 3.18, 3.13, 2.9, 2.52, 2.36, 2.34, 2.04, 1.99, 1.98, 1.96, 1.91, 1.83, 1.6, 1.56, 1.54, 1.54, 1.29]\n",
      "heart chd cardiac age disease cvd coronary early cardiovascular years risk young ihd ecg hearts later bradycardia atherosclerosis hf hr\n",
      "7 MED-1951 67.23240661621094 not-eval\n",
      "[4.05, 3.81, 3.1, 2.77, 2.76, 2.1, 2.02, 2.01, 1.93, 1.75, 1.75, 1.73, 1.68, 1.6, 1.59, 1.57, 1.55, 1.5, 1.3, 1.26]\n",
      "childhood children birth child early development late pediatric age infants onset preterm developmental adolescence paediatric later period premature timing born\n",
      "8 MED-4950 66.96183776855469 not-eval\n",
      "[3.43, 3.2, 3.08, 3.02, 2.63, 2.22, 2.15, 2.14, 1.89, 1.83, 1.81, 1.74, 1.67, 1.58, 1.56, 1.56, 1.42, 1.41, 1.37, 1.35]\n",
      "early children onset age childhood adolescence boys timing development earlier young developmental adolescents youth birth later period puberty child years\n",
      "9 MED-1996 66.83843231201172 not-eval\n",
      "[5.17, 4.3, 3.23, 2.83, 2.76, 2.7, 2.65, 2.64, 2.63, 2.57, 2.32, 2.32, 2.13, 1.54, 1.5, 1.46, 1.42, 1.33, 1.3, 1.3]\n",
      "childhood children child youth pediatric paediatric age adolescents disease adolescence early young preschool adolescent boys pediatrics development onset school younger\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3954 10.787633895874023 not-eval\n",
      "[3.95, 2.6, 2.59, 1.98]\n",
      "heart children childhood disease\n",
      "1 MED-1548 9.019461631774902 not-eval\n",
      "[4.73, 2.64, 2.08, 0.19]\n",
      "heart disease children baby\n",
      "2 MED-4919 7.668177604675293 not-eval\n",
      "[2.85, 2.78, 1.8, 0.41, 0.16]\n",
      "children disease childhood baby long\n",
      "3 MED-2590 7.661012649536133 not-eval\n",
      "[4.51, 2.76, 0.15, 0.12, 0.11]\n",
      "heart disease myocardium bacterial long\n",
      "4 MED-1366 7.110385417938232 not-eval\n",
      "[3.7, 2.02, 1.3]\n",
      "heart disease children\n",
      "5 MED-2479 6.958315849304199 not-eval\n",
      "[2.49, 1.76, 0.88, 0.5, 0.35]\n",
      "children disease childhood bacterial baby\n",
      "6 MED-1722 6.721230506896973 not-eval\n",
      "[2.86, 1.88, 1.78, 0.42, 0.15]\n",
      "children disease childhood baby bacterial\n",
      "7 MED-1996 6.688912391662598 not-eval\n",
      "[3.03, 1.79, 1.37, 0.36, 0.12]\n",
      "children childhood disease baby bacterial\n",
      "8 MED-3425 6.665884017944336 not-eval\n",
      "[3.6, 2.2, 0.31]\n",
      "heart disease children\n",
      "9 MED-4613 6.64697265625 1\n",
      "[4.0, 2.49]\n",
      "heart disease\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3954 18.944347381591797 not-eval\n",
      "[5.05, 4.86, 4.48, 3.62, 0.34, 0.28, 0.24]\n",
      "heart disease childhood children infancy age fever\n",
      "1 MED-3979 14.423734664916992 not-eval\n",
      "[5.3, 3.46, 3.43, 1.27, 0.87, 0.39, 0.13]\n",
      "children childhood disease illness fever age infancy\n",
      "2 MED-2590 14.417108535766602 not-eval\n",
      "[5.26, 5.02, 2.34, 1.37, 0.44]\n",
      "disease heart children myocardial cardiovascular\n",
      "3 MED-1996 14.32397747039795 not-eval\n",
      "[4.97, 4.28, 3.79, 1.0, 0.22]\n",
      "children disease childhood fever age\n",
      "4 MED-2484 13.659724235534668 not-eval\n",
      "[4.68, 4.0, 3.58, 1.34]\n",
      "childhood children disease fever\n",
      "5 MED-2218 13.19542121887207 not-eval\n",
      "[5.54, 4.36, 1.74, 0.96, 0.78, 0.46, 0.34]\n",
      "disease heart children illness fever cardiovascular age\n",
      "6 MED-1548 12.898365020751953 not-eval\n",
      "[5.1, 4.21, 3.78, 1.16]\n",
      "heart disease children cardiovascular\n",
      "7 MED-1680 12.866908073425293 not-eval\n",
      "[4.22, 2.93, 2.54, 1.97, 0.77, 0.21]\n",
      "disease heart children myocardial cardiovascular age\n",
      "8 MED-1987 12.627806663513184 not-eval\n",
      "[5.07, 3.71, 1.59, 0.92, 0.3, 0.22]\n",
      "children childhood disease fever illness age\n",
      "9 MED-1366 12.513051986694336 not-eval\n",
      "[5.25, 4.39, 2.66, 0.21]\n",
      "heart disease children illness\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3954 18.710073471069336 not-eval\n",
      "[4.99, 3.64, 3.34, 2.55, 1.06, 1.01, 0.9, 0.76, 0.35, 0.13]\n",
      "childhood heart disease child cause teen diseases hearts pre gene\n",
      "1 MED-3253 18.670602798461914 2\n",
      "[3.56, 3.33, 2.91, 2.11, 1.32, 0.97, 0.92, 0.75, 0.61, 0.56, 0.25, 0.13, 0.11]\n",
      "heart childhood disease child start teen cause hearts diseases when begin gene early\n",
      "2 MED-1949 16.173206329345703 not-eval\n",
      "[3.71, 3.52, 2.64, 1.47, 1.4, 0.94, 0.89, 0.53, 0.34, 0.23, 0.14, 0.11]\n",
      "disease heart child pre childhood cause diseases when teen start baby first\n",
      "3 MED-1996 16.133638381958008 not-eval\n",
      "[4.4, 3.06, 2.62, 1.62, 1.4, 1.23, 0.87, 0.4, 0.17, 0.11, 0.1]\n",
      "childhood disease child heart teen cause diseases pre gene when early\n",
      "4 MED-1994 15.264307022094727 not-eval\n",
      "[3.67, 3.16, 2.47, 1.42, 1.28, 1.06, 1.02, 0.8, 0.14]\n",
      "childhood disease child pre teen cause diseases heart gene\n",
      "5 MED-2590 14.389830589294434 not-eval\n",
      "[5.88, 5.01, 1.92, 1.27, 0.18]\n",
      "heart disease hearts diseases cause\n",
      "6 MED-4315 14.27379035949707 not-eval\n",
      "[6.11, 4.2, 2.03, 0.91, 0.87]\n",
      "heart disease hearts cause diseases\n",
      "7 MED-2476 14.206658363342285 not-eval\n",
      "[4.25, 3.51, 2.57, 1.46, 1.04, 0.55, 0.3, 0.12]\n",
      "childhood disease child diseases cause teen pre gene\n",
      "8 MED-1932 13.919013023376465 not-eval\n",
      "[4.45, 2.76, 2.57, 1.04, 0.92, 0.73, 0.51, 0.3, 0.3, 0.28]\n",
      "childhood child disease cause teen diseases when gene pre happen\n",
      "9 MED-1190 13.688178062438965 not-eval\n",
      "[4.82, 3.47, 2.34, 1.32, 0.74, 0.57, 0.16, 0.13]\n",
      "heart disease child hearts cause diseases gene childhood\n"
     ]
    }
   ],
   "source": [
    "observe_model = [\"adalm\", \"dapt-splade-59372\", \"dapt-59372\", \"splade\"]\n",
    "for qid in qids_dapt_worse_adalm_better:\n",
    "    print(\"----------------------------\")\n",
    "    print(queries[qid])\n",
    "    for model_name in observe_model:\n",
    "        print(\"-------------\")\n",
    "        print(model_name)\n",
    "        analysis(model_name, qid, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bb462357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "How to Reduce Exposure to Alkylphenols Through Your Diet\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2658 113.0926742553711 1\n",
      "[5.96, 5.24, 4.23, 3.65, 3.58, 3.53, 2.77, 2.63, 2.48, 2.47, 2.46, 2.44, 2.33, 2.26, 1.95, 1.87, 1.86, 1.85, 1.76, 1.64]\n",
      "alkylphenolphenol op nonyl phthalate alkyl chemicals phenol ap dehp edc bpa phenols bisphenol phenolic np endocrine compound pp\n",
      "1 MED-2661 101.48649597167969 2\n",
      "[5.48, 4.41, 4.08, 3.97, 3.55, 3.16, 3.13, 2.4, 2.39, 2.18, 2.13, 2.1, 2.04, 2.04, 2.02, 1.85, 1.66, 1.53, 1.51, 1.48]\n",
      "alkylphenol opphenol nonyl phthalate ap alkyl dehp chemicals aps compound bpa np phenol phenols pp opp fin phenolic\n",
      "2 MED-2651 95.25385284423828 2\n",
      "[5.26, 4.38, 4.02, 3.85, 3.32, 3.16, 2.18, 2.14, 2.12, 2.12, 2.04, 1.98, 1.88, 1.86, 1.85, 1.79, 1.63, 1.62, 1.58, 1.57]\n",
      "alkylp opphenolhenol nonyl phthalate phenols alkyl dehp phenol np chemicals ap phenolic oil compound opp ohp bpa pp\n",
      "3 MED-118 95.25385284423828 2\n",
      "[5.26, 4.38, 4.02, 3.85, 3.32, 3.16, 2.18, 2.14, 2.12, 2.12, 2.04, 1.98, 1.88, 1.86, 1.85, 1.79, 1.63, 1.62, 1.58, 1.57]\n",
      "alkylp opphenolhenol nonyl phthalate phenols alkyl dehp phenol np chemicals ap phenolic oil compound opp ohp bpa pp\n",
      "4 MED-2644 95.02348327636719 2\n",
      "[5.52, 4.84, 4.79, 4.12, 3.51, 3.0, 2.46, 2.38, 2.32, 2.29, 2.25, 2.07, 1.96, 1.95, 1.83, 1.82, 1.79, 1.77, 1.74, 1.56]\n",
      "alkylpphenolhenol nonyl phthalate phenol dehp alkyl chemicals phenols compound ap bisphenol bpa phenolic pp np op nitrophenol p\n",
      "5 MED-2652 73.09500122070312 2\n",
      "[4.67, 3.63, 3.08, 3.03, 2.83, 2.8, 2.74, 2.35, 2.31, 1.83, 1.66, 1.61, 1.6, 1.51, 1.39, 1.33, 1.32, 1.27, 1.14, 1.06]\n",
      "phthalate alkylphenol dehp bisphenol bpa chemicals compoundphenol chemical compounds nonyl fragrance air plasticizer pesticide edc endocrine benzene phenolic\n",
      "6 MED-2653 71.950439453125 2\n",
      "[4.4, 4.02, 3.8, 3.25, 3.24, 2.1, 2.1, 1.7, 1.63, 1.61, 1.6, 1.57, 1.56, 1.48, 1.43, 1.4, 1.36, 1.34, 1.25, 1.19]\n",
      "##phenol op nonyl alkylp phthalate np dehp chemicals nitrophenol compound opp pp contaminant bpa no2 bisphenol phenol npe fin phenols\n",
      "7 MED-2662 68.66486358642578 2\n",
      "[4.6, 4.13, 3.16, 2.88, 2.76, 2.3, 1.84, 1.83, 1.76, 1.72, 1.7, 1.7, 1.63, 1.47, 1.44, 1.43, 1.43, 1.37, 1.32, 1.18]\n",
      "phthalate dehp nonylphenol chemicals bpa compound dep edc chemical np bisphenol op contaminant pollutants plasticizer pollution endocrine environmental exposure\n",
      "8 MED-2654 64.33935546875 1\n",
      "[4.31, 3.85, 3.25, 2.73, 2.2, 2.07, 1.94, 1.9, 1.83, 1.72, 1.67, 1.63, 1.59, 1.58, 1.5, 1.43, 1.43, 1.4, 1.3, 1.29]\n",
      "##phenol nonyl phthalate alkylp dehp nphenol chemicals endocrine compound nitrophenol bisphenol npe edc bpa no2 food exposure phenol phenols\n",
      "9 MED-5316 61.80154037475586 not-eval\n",
      "[3.38, 3.17, 2.77, 2.32, 2.26, 2.06, 2.05, 1.94, 1.92, 1.91, 1.85, 1.83, 1.75, 1.64, 1.58, 1.49, 1.44, 1.32, 1.23, 1.08]\n",
      "phenol phthalate phenols chemicals phenolic compound dep nitrophenol bpa aniline benzene exposure dehp chemical chlorophenol nphenol cresol pp fragrance\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2644 10.95060920715332 2\n",
      "[3.71, 2.83, 2.72, 0.79, 0.7, 0.12]\n",
      "##phenolkyl alenol phenolss\n",
      "1 MED-2658 10.930947303771973 1\n",
      "[3.97, 2.91, 2.83, 0.59, 0.38, 0.18]\n",
      "##phenol alkyl phenolsenols\n",
      "2 MED-2661 10.169252395629883 2\n",
      "[3.37, 2.87, 2.55, 0.44, 0.27, 0.18]\n",
      "##phenolkyl al phenolsenols\n",
      "3 MED-2651 9.294334411621094 2\n",
      "[3.42, 2.54, 2.03, 0.44, 0.41, 0.32, 0.28]\n",
      "##phenolkyl al phenols dietenol exposure\n",
      "4 MED-118 9.294334411621094 2\n",
      "[3.42, 2.54, 2.03, 0.44, 0.41, 0.32, 0.28]\n",
      "##phenolkyl al phenols dietenol exposure\n",
      "5 MED-2652 9.209200859069824 2\n",
      "[3.06, 1.39, 1.35, 0.72, 0.42, 0.21, 0.15]\n",
      "##phenol alkyl exposure phenolsenols\n",
      "6 MED-2647 6.542079925537109 1\n",
      "[2.76, 1.53, 0.87, 0.68, 0.37, 0.21, 0.12]\n",
      "exposurephenol diet al phenolskyls\n",
      "7 MED-1164 6.273993492126465 not-eval\n",
      "[2.25, 1.63, 1.17, 1.1, 0.66]\n",
      "exposure alkyl diet reduce\n",
      "8 MED-1847 6.109560489654541 not-eval\n",
      "[4.22, 1.0, 0.62, 0.12, 0.1]\n",
      "alphenol phenolsenols\n",
      "9 MED-1845 5.222037315368652 not-eval\n",
      "[3.85, 1.29]\n",
      "al diet\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2644 21.738418579101562 2\n",
      "[6.15, 5.11, 3.01, 2.02, 1.28, 1.22, 1.21, 0.92, 0.41, 0.41]\n",
      "alphenolkyl methyl aldehydes alkaline aromatic aroma ph methanol\n",
      "1 MED-2658 20.643884658813477 1\n",
      "[6.32, 4.43, 3.48, 2.11, 1.59, 1.17, 1.08, 0.29, 0.17]\n",
      "alphenolkyl methyl aldehydes aromatic acetaldehyde alkaline aroma\n",
      "2 MED-4908 18.759605407714844 not-eval\n",
      "[6.73, 2.71, 2.55, 2.41, 2.19, 1.88, 0.26]\n",
      "al aldehydes alkaline acetaldehyde toxicity methyl chloroform\n",
      "3 MED-2661 18.39940071105957 2\n",
      "[6.05, 3.78, 2.64, 2.13, 1.52, 0.91, 0.82, 0.6, 0.16]\n",
      "alphenolkyl methyl aldehydes aromatic alkaline acetaldehyde methanol\n",
      "4 MED-3488 17.56268310546875 not-eval\n",
      "[7.28, 2.47, 2.1, 2.07, 1.61, 1.51, 0.46]\n",
      "al alkaline aldehydes acetaldehyde toxicity methyl ph\n",
      "5 MED-1851 16.831159591674805 not-eval\n",
      "[6.71, 2.83, 2.54, 2.29, 1.91, 0.62, 0.5, 0.24]\n",
      "al alkaline acetaldehyde aldehydes methyl toxicity chloroform ph\n",
      "6 MED-1164 16.798343658447266 not-eval\n",
      "[3.19, 3.05, 2.82, 2.38, 2.35, 1.55, 0.32, 0.24]\n",
      "al exposure diet exposures methyl toxicitykyl acetaldehyde\n",
      "7 MED-1850 16.549436569213867 not-eval\n",
      "[6.63, 3.0, 2.7, 2.51, 0.57, 0.56, 0.5]\n",
      "al alkaline acetaldehyde aldehydes methyl chloroform toxicity\n",
      "8 MED-4909 15.977835655212402 not-eval\n",
      "[7.03, 2.41, 2.31, 2.11, 1.91, 0.53]\n",
      "al aldehydes alkaline acetaldehyde methyl chloroform\n",
      "9 MED-3087 15.461750030517578 not-eval\n",
      "[6.96, 2.62, 2.41, 2.24, 0.63, 0.12]\n",
      "al alkaline aldehydes acetaldehyde chloroform methanol\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-1961 17.539628982543945 not-eval\n",
      "[3.53, 2.74, 1.68, 1.44, 1.32, 1.16, 0.92, 0.87, 0.87, 0.83, 0.44, 0.42, 0.34, 0.26, 0.21, 0.19, 0.13]\n",
      "exposure reduce food diet to reduction for through drug decrease treatment exposed pollution prevent doing habitat chemical\n",
      "1 MED-1169 17.078235626220703 not-eval\n",
      "[3.11, 2.4, 2.04, 2.03, 1.55, 1.46, 0.97, 0.75, 0.54, 0.33, 0.33, 0.32, 0.32, 0.19, 0.18, 0.14, 0.12, 0.11]\n",
      "exposure reduce diet foodky reduction to decrease for exposedlp pollution drug, prevent habitat chemical doing\n",
      "2 MED-5120 15.517864227294922 not-eval\n",
      "[2.89, 2.4, 1.58, 1.52, 1.19, 1.12, 1.01, 0.89, 0.75, 0.7, 0.46, 0.2, 0.19, 0.16, 0.13]\n",
      "##ky exposure reduce al diet for food drug treatment decrease, doing exposed mechanism habitat\n",
      "3 MED-999 15.476358413696289 not-eval\n",
      "[3.2, 1.89, 1.87, 1.66, 1.38, 0.88, 0.79, 0.64, 0.44, 0.43, 0.4, 0.3, 0.26, 0.26, 0.26, 0.22, 0.16, 0.15, 0.14]\n",
      "exposurehen reduce food diet for through reduction pollution exposed drug treatment, habitat decrease chemical doing mechanism prevent\n",
      "4 MED-2644 14.307415008544922 2\n",
      "[3.26, 2.27, 1.69, 1.41, 1.19, 0.95, 0.78, 0.74, 0.45, 0.38, 0.36, 0.32, 0.22, 0.1]\n",
      "##kyhen alol exposure drug forlp exposed,ols treatment chemical mechanism\n",
      "5 MED-1174 14.103506088256836 not-eval\n",
      "[3.2, 2.63, 2.0, 1.84, 0.74, 0.66, 0.63, 0.48, 0.44, 0.39, 0.32, 0.28, 0.25, 0.18, 0.17, 0.16, 0.15, 0.14]\n",
      "exposure diet reduce food decrease through for drug exposed to pollution reduction treatment prevent habitat, doing chemical\n",
      "6 MED-3925 13.880084991455078 not-eval\n",
      "[2.6, 2.16, 1.92, 1.86, 1.05, 1.03, 0.8, 0.51, 0.44, 0.36, 0.29, 0.28, 0.15, 0.13]\n",
      "diet reduce food exposure reduction for drug treatment decreaseol prevent to, doing\n",
      "7 MED-3609 13.678173065185547 not-eval\n",
      "[2.81, 1.29, 1.26, 1.1, 0.97, 0.92, 0.87, 0.86, 0.83, 0.67, 0.46, 0.28, 0.23, 0.16, 0.14, 0.13, 0.11]\n",
      "exposure reduce diet for drug reduction treatment decrease food al,ol exposed doing pollution prevent mechanism\n",
      "8 MED-1829 13.530107498168945 not-eval\n",
      "[3.17, 2.61, 1.28, 1.16, 1.13, 0.91, 0.7, 0.59, 0.45, 0.35, 0.25, 0.22, 0.17, 0.14]\n",
      "exposure diet reduce reduction food drug for treatment mechanism, exposed preventol pollution\n",
      "9 MED-2651 13.478631019592285 2\n",
      "[2.89, 2.42, 1.81, 1.7, 1.51, 1.47, 1.41, 0.71, 0.61, 0.37, 0.32, 0.23, 0.21, 0.21, 0.21, 0.15]\n",
      "##ky exposurehen food diet alollpols drug for, habitat exposed pollution chemical\n",
      "----------------------------\n",
      "cocaine\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3044 59.70397186279297 1\n",
      "[7.27, 3.26, 3.15, 3.01, 2.81, 2.77, 2.01, 1.98, 1.97, 1.88, 1.8, 1.59, 1.58, 1.58, 1.54, 1.34, 1.29, 1.27, 1.14, 1.08]\n",
      "cocaine craving crack drug psychostimulant stimulant addictive cc illicit methamphetamine addiction users ketamine cannabis psychoactive heroinecgonine amphetamine substance mdma\n",
      "1 MED-3052 41.63512420654297 1\n",
      "[4.18, 3.15, 2.84, 2.8, 2.28, 2.27, 2.19, 1.82, 1.57, 1.53, 1.48, 1.47, 1.37, 1.15, 1.08, 1.08, 0.95, 0.94, 0.84, 0.74]\n",
      "cocaine drug addiction addictive stimulant psychostimulant craving illicit drugs substance methamphetamine psychoactive amphetamine epidemic heroin cannabis bz nicotine abuse abstinence\n",
      "2 MED-952 37.62549591064453 not-eval\n",
      "[4.01, 3.35, 2.33, 2.02, 1.73, 1.7, 1.45, 1.45, 1.28, 1.27, 1.26, 1.25, 1.25, 1.23, 1.21, 1.07, 1.01, 0.95, 0.9, 0.86]\n",
      "cocaine cannabis cannabinoids crack psychoactive drug stimulant illicit tobacco substance users use nicotine addictive ketamine thc smoking addiction bz cc\n",
      "3 MED-3055 37.32232666015625 1\n",
      "[4.16, 3.21, 2.74, 2.7, 2.14, 2.1, 2.03, 1.66, 1.59, 1.41, 1.39, 1.31, 1.25, 1.01, 0.96, 0.9, 0.79, 0.71, 0.68, 0.64]\n",
      "cocaine drug addiction addictive craving psychostimulant stimulant illicit drugs psychoactive methamphetamine amphetamine substance epidemic cannabis bz heroin nicotine reinforcing abuse\n",
      "4 MED-5248 36.41144561767578 not-eval\n",
      "[4.38, 2.92, 2.65, 2.15, 1.97, 1.92, 1.43, 1.34, 1.29, 1.2, 1.18, 1.07, 0.91, 0.88, 0.81, 0.81, 0.81, 0.8, 0.8, 0.72]\n",
      "cocaine stimulant crack drug craving addictive addiction cc bz abuse substance nicotine cra administration tobacco consumption cannabis caffeine stimulants psychoactive\n",
      "5 MED-3054 35.14883804321289 1\n",
      "[3.45, 2.99, 2.83, 2.52, 2.3, 2.16, 2.1, 1.88, 1.45, 1.31, 1.07, 1.06, 1.04, 0.87, 0.83, 0.83, 0.73, 0.72, 0.72, 0.66]\n",
      "cocaine addiction addictive drug stimulant substance craving psychostimulant psychoactive amphetamine drugs abuse illicit bz behavior use methamphetamine epidemic nicotine compulsive\n",
      "6 MED-5159 34.49909210205078 not-eval\n",
      "[3.79, 3.26, 2.2, 1.76, 1.55, 1.51, 1.41, 1.36, 1.32, 1.3, 1.22, 1.2, 1.13, 1.12, 1.04, 1.02, 1.02, 0.86, 0.79, 0.73]\n",
      "cocaine cannabis cannabinoids crack drug psychoactive use users tobacco nicotine smoking substance illicit cc thc ketamine stimulant addictive marijuana cannabinoid\n",
      "7 MED-3806 33.77843475341797 not-eval\n",
      "[3.28, 2.45, 2.0, 1.76, 1.61, 1.6, 1.5, 1.47, 1.45, 1.41, 1.33, 1.31, 1.23, 1.2, 1.1, 0.99, 0.93, 0.91, 0.87, 0.78]\n",
      "cocaine stimulant drug amphetamine addictive cannabis illicit psychoactive crack methamphetamine cannabinoids ketamine abuse nicotine users addiction administration psychostimulant substance bz\n",
      "8 MED-3146 32.63148498535156 not-eval\n",
      "[3.23, 2.32, 2.16, 1.99, 1.56, 1.55, 1.53, 1.42, 1.28, 1.18, 1.13, 1.12, 1.12, 1.05, 1.04, 1.03, 0.95, 0.82, 0.75, 0.72]\n",
      "drug cocaine heroin illicit drugs ketamine addictive cannabis addiction cannabinoids stimulant crack codeine substance psychoactive fentanyl methamphetamine nicotine use administration\n",
      "9 MED-3058 31.56387710571289 1\n",
      "[3.58, 3.02, 2.79, 2.05, 1.86, 1.74, 1.44, 1.44, 1.44, 1.38, 1.07, 1.03, 0.79, 0.79, 0.74, 0.68, 0.62, 0.53, 0.39, 0.35]\n",
      "cocaine addictive addiction craving psychostimulant stimulant drug illicit psychoactive substance epidemic amphetamine bz methamphetamine abuse cannabis compulsive behavior consumption research\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3044 10.874884605407715 1\n",
      "[9.47, 2.12]\n",
      "cocaine brain\n",
      "1 MED-3055 3.368903398513794 1\n",
      "[2.56, 0.78]\n",
      "brain dopamine\n",
      "2 MED-3052 3.2186520099639893 1\n",
      "[2.7, 0.56]\n",
      "brain dopamine\n",
      "3 MED-3546 3.1234467029571533 1\n",
      "[2.59, 0.49]\n",
      "brain dopamine\n",
      "4 MED-3057 3.0691306591033936 1\n",
      "[3.11]\n",
      "brain\n",
      "5 MED-3046 3.0369598865509033 1\n",
      "[2.56, 0.45]\n",
      "brain dopamine\n",
      "6 MED-4721 3.0205488204956055 not-eval\n",
      "[2.96]\n",
      "brain\n",
      "7 MED-1505 2.8612780570983887 not-eval\n",
      "[2.86]\n",
      "brain\n",
      "8 MED-4306 2.8593010902404785 not-eval\n",
      "[2.63, 0.23]\n",
      "brain dopamine\n",
      "9 MED-2664 2.8292770385742188 not-eval\n",
      "[2.83]\n",
      "brain\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3044 13.211000442504883 1\n",
      "[7.12, 2.74, 1.82, 0.98, 0.58, 0.29, 0.28]\n",
      "cocaine arousal hypnotic paf drugs baselines exposures\n",
      "1 MED-1349 8.055644989013672 not-eval\n",
      "[3.2, 2.11, 0.81, 0.77, 0.52, 0.38, 0.26]\n",
      "arousal hypnotic drugs baselines paf phenytoin norepinephrine\n",
      "2 MED-3038 6.426416397094727 1\n",
      "[2.82, 1.92, 0.76, 0.72, 0.21]\n",
      "arousal hypnotic drugs baselines norepinephrine\n",
      "3 MED-3773 6.239631652832031 not-eval\n",
      "[3.95, 1.36, 0.88]\n",
      "arousal baselines hypnotic\n",
      "4 MED-1830 6.2364606857299805 not-eval\n",
      "[3.18, 1.17, 1.16, 0.88]\n",
      "arousal baselines drugs hypnotic\n",
      "5 MED-1932 5.836416721343994 not-eval\n",
      "[3.61, 1.08, 0.83, 0.3]\n",
      "arousal baselines paf exposures\n",
      "6 MED-3055 5.773306369781494 1\n",
      "[3.3, 1.01, 0.95, 0.54, 0.14]\n",
      "arousal drugs baselines norepinephrine exposures\n",
      "7 MED-3772 5.668209075927734 not-eval\n",
      "[3.1, 1.27, 1.14, 0.16]\n",
      "arousal baselines hypnotic exposures\n",
      "8 MED-3775 5.566057205200195 not-eval\n",
      "[3.07, 1.2, 0.76, 0.12]\n",
      "arousal baselines hypnotic exposures\n",
      "9 MED-4158 5.486260414123535 not-eval\n",
      "[3.13, 1.07, 0.75, 0.68, 0.19]\n",
      "arousal baselines drugs hypnotic exposures\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3044 13.376989364624023 1\n",
      "[5.42, 3.63, 3.09, 0.34, 0.27, 0.26, 0.21, 0.2]\n",
      "cocaine coca drug brooke genus is colin him\n",
      "1 MED-2173 7.3193206787109375 not-eval\n",
      "[2.6, 0.92, 0.84, 0.66, 0.38, 0.31, 0.29, 0.27, 0.24, 0.12]\n",
      "drug chemical cocaine is genus coca ( for him from\n",
      "2 MED-2219 6.777724742889404 not-eval\n",
      "[4.79, 1.1, 0.28, 0.24, 0.12]\n",
      "coca drug chemical him like\n",
      "3 MED-3585 6.552940368652344 not-eval\n",
      "[4.18, 1.49, 0.3, 0.23, 0.19]\n",
      "coca drug for chemical him\n",
      "4 MED-2818 6.064846515655518 not-eval\n",
      "[2.1, 0.95, 0.71, 0.45, 0.43, 0.43, 0.31, 0.26, 0.26]\n",
      "drug is genus him chemical for are from colin\n",
      "5 MED-2093 5.906266689300537 not-eval\n",
      "[2.28, 1.05, 0.55, 0.54, 0.52, 0.37, 0.32, 0.25]\n",
      "drug is genus for chemical him ( are\n",
      "6 MED-4544 5.716602325439453 not-eval\n",
      "[1.89, 1.03, 0.79, 0.73, 0.43, 0.4, 0.39, 0.37]\n",
      "drug coca genus is for him are chemical\n",
      "7 MED-2815 5.710813999176025 not-eval\n",
      "[2.0, 0.84, 0.73, 0.51, 0.48, 0.45, 0.32, 0.18]\n",
      "drug is genus chemical for him are from\n",
      "8 MED-2065 5.710577011108398 not-eval\n",
      "[1.98, 0.88, 0.82, 0.63, 0.41, 0.4, 0.2, 0.15, 0.12]\n",
      "drug is genus chemical him for are contain from\n",
      "9 MED-2817 5.603695392608643 not-eval\n",
      "[1.97, 0.77, 0.71, 0.54, 0.48, 0.45, 0.28, 0.27]\n",
      "drug is genus for chemical him are from\n",
      "----------------------------\n",
      "Phytates for the Treatment of Cancer\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2585 96.91694641113281 2\n",
      "[5.03, 4.83, 4.28, 3.51, 3.46, 2.82, 2.77, 2.73, 2.49, 2.26, 2.26, 2.11, 2.01, 1.85, 1.78, 1.56, 1.55, 1.53, 1.53, 1.52]\n",
      "phytate cancer inositol ip insp anticancer phytic cancers phosphate tumor antitumor ihp inhibition polyphosphate chemotherapy gip p cancerous treatment malignant\n",
      "1 MED-2578 93.04063415527344 2\n",
      "[7.24, 5.73, 4.62, 3.94, 3.76, 3.26, 2.68, 2.53, 2.53, 2.26, 1.82, 1.71, 1.71, 1.67, 1.64, 1.63, 1.59, 1.57, 1.52, 1.52]\n",
      "phytate phytic cancer phytase inositol insp cancers ip phosphate gip adenocarcinoma p cancerous opn polyphosphate tumor ihp inhibition phosphorus chemopreventive\n",
      "2 MED-2544 87.57078552246094 2\n",
      "[6.86, 5.86, 4.63, 3.89, 3.58, 3.13, 2.74, 2.45, 2.43, 2.03, 1.76, 1.74, 1.63, 1.57, 1.56, 1.53, 1.53, 1.52, 1.47, 1.47]\n",
      "phytate phytic cancer phytase inositol insp cancers ip phosphate gip adenocarcinoma cancerous p chemopreventive opn polyphosphate phosphorus tumor inorganic phosphonate\n",
      "3 MED-2579 87.02503967285156 2\n",
      "[5.08, 4.63, 3.77, 3.35, 3.07, 3.03, 2.75, 2.24, 1.75, 1.75, 1.71, 1.69, 1.67, 1.61, 1.57, 1.47, 1.46, 1.44, 1.4, 1.31]\n",
      "phytate cancer inositol ip insp phytic cancers phosphate anticancer polyphosphate cancerous ihp adenocarcinoma p tumor chemopreventive antitumor treatment inorganic inhibition\n",
      "4 MED-2568 82.96197509765625 2\n",
      "[4.66, 4.07, 3.9, 3.75, 3.55, 2.53, 2.27, 2.07, 2.01, 1.97, 1.92, 1.89, 1.71, 1.7, 1.45, 1.44, 1.38, 1.32, 1.29, 1.25]\n",
      "cancer insp phytate inositol ip cancers phosphate tumor anticancer ihp gip antitumor inhibition polyphosphate cancerous p inhibitor malignant oncology phytic\n",
      "5 MED-2988 82.58548736572266 2\n",
      "[7.54, 5.8, 4.83, 3.73, 3.41, 2.78, 2.73, 2.52, 2.07, 1.96, 1.84, 1.84, 1.72, 1.62, 1.61, 1.56, 1.52, 1.49, 1.31, 1.24]\n",
      "phytate phytic phytase inositol insp phosphate gip ip legume phosphatase ihp phosphonate phosphorus polyphosphate inorganic legumes p opn mineral acid\n",
      "6 MED-2546 81.24130249023438 2\n",
      "[4.37, 4.35, 3.77, 3.52, 3.07, 2.48, 2.05, 2.03, 2.02, 1.93, 1.86, 1.8, 1.79, 1.78, 1.77, 1.66, 1.55, 1.46, 1.32, 1.29]\n",
      "phytate cancer inositol ip insp phosphate cancers phytic treatment ihp inhibition tumor metastasis polyphosphate metastatic p adenocarcinoma inhibitor antimetastatic melanoma\n",
      "7 MED-2575 79.91035461425781 2\n",
      "[4.96, 4.33, 3.87, 3.77, 3.49, 3.34, 2.43, 2.08, 1.99, 1.82, 1.81, 1.73, 1.71, 1.59, 1.5, 1.44, 1.38, 1.34, 1.27, 1.23]\n",
      "phytate cancer inositol phytic ip insp phosphate ihp cancers polyphosphate adenocarcinoma p tumor inhibitor inhibition carcinoma phytase canceroushosphate metastasis\n",
      "8 MED-2574 77.8014144897461 2\n",
      "[4.88, 4.76, 3.97, 3.44, 3.31, 2.65, 2.64, 2.4, 2.33, 2.32, 1.97, 1.89, 1.81, 1.73, 1.59, 1.46, 1.31, 1.26, 1.24, 1.19]\n",
      "phytate cancer inositol ip insp cancers phytic phosphate anticancer tumor antitumor ihp gip polyphosphate cancerous p chemopreventive malignant inhibition chemotherapy\n",
      "9 MED-4319 75.85610961914062 2\n",
      "[7.93, 5.9, 4.16, 3.9, 3.65, 2.92, 2.9, 2.58, 1.97, 1.92, 1.69, 1.66, 1.65, 1.62, 1.55, 1.35, 1.29, 1.27, 1.21, 1.16]\n",
      "phytate phytic phytase inositol insp phosphate gip ip ihp phosphonate p opn polyphosphate inorganic phosphorus mpt phosphatase mineral pyrophosphate acid\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2578 8.744863510131836 2\n",
      "[5.57, 3.08]\n",
      "phytate cancer\n",
      "1 MED-2988 6.86778450012207 2\n",
      "[6.3, 0.33, 0.23]\n",
      "phytate cancers\n",
      "2 MED-2989 6.522315979003906 1\n",
      "[6.47]\n",
      "phytate\n",
      "3 MED-2985 6.477375030517578 1\n",
      "[6.48]\n",
      "phytate\n",
      "4 MED-4319 6.4417524337768555 2\n",
      "[6.36]\n",
      "phytate\n",
      "5 MED-2987 6.411988735198975 1\n",
      "[6.53]\n",
      "phytate\n",
      "6 MED-2983 5.840980529785156 1\n",
      "[5.51, 0.29]\n",
      "phytates\n",
      "7 MED-3729 5.2262864112854 1\n",
      "[2.99, 0.87, 0.75, 0.57]\n",
      "cancer drugs treatments\n",
      "8 MED-2986 5.1832122802734375 1\n",
      "[5.52]\n",
      "phytate\n",
      "9 MED-3550 5.034662246704102 not-eval\n",
      "[3.29, 1.01, 0.71]\n",
      "cancer drugs treatment\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2578 15.029195785522461 2\n",
      "[5.64, 5.35, 2.46, 0.9, 0.68]\n",
      "cancer phytate carcinogenesis aromatic tannins\n",
      "1 MED-4319 14.498517036437988 2\n",
      "[6.73, 2.27, 2.23, 1.3, 0.49, 0.47, 0.45, 0.44, 0.13]\n",
      "phytate phthalate aromatic tannins 4mi sulfate baselines retirement me\n",
      "2 MED-2989 14.196030616760254 1\n",
      "[6.83, 2.08, 1.86, 1.37, 0.65, 0.64, 0.5, 0.14, 0.13]\n",
      "phytate aromatic phthalate tannins 4mi retirement baselines me sulfate\n",
      "3 MED-2988 14.07994556427002 2\n",
      "[6.39, 2.37, 1.66, 1.62, 1.27, 0.31, 0.28, 0.1]\n",
      "phytate aromatic cancer phthalate tannins xanthine retirement me\n",
      "4 MED-2983 13.994029998779297 1\n",
      "[6.38, 2.28, 1.81, 1.61, 0.55, 0.52, 0.46, 0.16, 0.16]\n",
      "phytate aromatic tannins phthalate sulfate baselines 4mi me xanthine\n",
      "5 MED-2985 13.969767570495605 1\n",
      "[6.78, 2.19, 1.73, 1.38, 0.56, 0.45, 0.42, 0.28, 0.19]\n",
      "phytate aromatic phthalate tannins sulfate retirement baselines 4mi me\n",
      "6 MED-2987 12.232975006103516 1\n",
      "[6.69, 1.96, 1.55, 1.27, 0.61, 0.36, 0.17, 0.17, 0.15]\n",
      "phytate aromatic phthalate tannins retirement baselines me 4mi xanthine\n",
      "7 MED-2627 11.746725082397461 not-eval\n",
      "[6.36, 2.58, 1.81, 0.99]\n",
      "cancer carcinogenesis aromatic retirement\n",
      "8 MED-4040 11.314582824707031 not-eval\n",
      "[5.26, 2.75, 1.48, 0.36]\n",
      "cancer aromatic carcinogenesis baselines\n",
      "9 MED-4493 11.259201049804688 not-eval\n",
      "[6.23, 3.1, 2.21]\n",
      "cancer carcinogenesis aromatic\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-2435 23.31549072265625 not-eval\n",
      "[5.4, 5.21, 2.84, 2.64, 2.18, 1.34, 0.64, 0.44, 0.42, 0.39, 0.39, 0.36, 0.28, 0.28, 0.26, 0.13]\n",
      "##yt cancer ph tumor treatment for drug treatments chemical food purpose doing use david genus habitat\n",
      "1 MED-4620 22.720226287841797 not-eval\n",
      "[5.47, 4.71, 3.14, 2.52, 2.05, 1.18, 0.46, 0.44, 0.43, 0.38, 0.36, 0.33, 0.32, 0.29, 0.23, 0.11]\n",
      "##yt cancer ph tumor treatment for purpose food genus drug treatments chemical doing habitat are gene\n",
      "2 MED-5010 22.720226287841797 not-eval\n",
      "[5.47, 4.71, 3.14, 2.52, 2.05, 1.18, 0.46, 0.44, 0.43, 0.38, 0.36, 0.33, 0.32, 0.29, 0.23, 0.11]\n",
      "##yt cancer ph tumor treatment for purpose food genus drug treatments chemical doing habitat are gene\n",
      "3 MED-3832 22.361183166503906 not-eval\n",
      "[5.63, 4.97, 3.27, 2.33, 1.73, 1.24, 0.73, 0.44, 0.42, 0.36, 0.33, 0.28, 0.2, 0.17, 0.12, 0.11]\n",
      "##yt cancer ph tumor treatment for drug genus chemical doing use food treatments habitat purpose gene\n",
      "4 MED-2578 22.27963638305664 2\n",
      "[5.79, 5.09, 3.13, 2.7, 2.61, 0.74, 0.5, 0.36, 0.33, 0.24, 0.21, 0.15, 0.14]\n",
      "##yt cancer phate tumor for food treatment drug chemical genus habitat composition\n",
      "5 MED-4391 21.466289520263672 not-eval\n",
      "[5.53, 5.36, 2.67, 2.2, 1.93, 0.66, 0.47, 0.42, 0.41, 0.36, 0.36, 0.32, 0.25, 0.17, 0.16]\n",
      "canceryt tumor ph treatment chemical genus drug treatments for david purpose food habitat gene\n",
      "6 MED-4650 21.451387405395508 not-eval\n",
      "[5.13, 4.34, 2.78, 2.36, 2.15, 1.46, 0.72, 0.4, 0.39, 0.38, 0.3, 0.3, 0.28, 0.24, 0.13]\n",
      "##yt cancer ph treatment tumor for drug food chemical genus purpose doing treatments gene use\n",
      "7 MED-3130 21.22015380859375 not-eval\n",
      "[4.9, 4.66, 2.5, 2.29, 2.29, 0.99, 0.94, 0.55, 0.4, 0.36, 0.34, 0.25, 0.12]\n",
      "##yt cancer ph treatment tumor forate drug gene treatments chemical doing use\n",
      "8 MED-3555 21.17129135131836 not-eval\n",
      "[5.84, 5.29, 3.27, 2.61, 0.78, 0.64, 0.46, 0.4, 0.34, 0.28, 0.26, 0.24, 0.2]\n",
      "##yt cancer ph tumor for genus drug david chemical treatment are food gene\n",
      "9 MED-4777 21.09051513671875 not-eval\n",
      "[4.58, 3.87, 2.46, 2.1, 1.87, 1.54, 1.47, 0.52, 0.5, 0.42, 0.36, 0.34, 0.29, 0.27, 0.2, 0.16, 0.14, 0.12]\n",
      "##yt cancer ph tumorate treatment for food drug purpose doing chemical habitat genus are treatments use gene\n",
      "----------------------------\n",
      "Veggies vs. Cancer\n",
      "-------------\n",
      "adalm\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/adalm-bio/GenQ-adalm-bio-splade/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4391 60.41245651245117 not-eval\n",
      "[5.19, 3.59, 3.16, 3.01, 2.65, 2.57, 2.49, 2.18, 2.12, 2.05, 1.79, 1.57, 1.57, 1.51, 1.46, 1.38, 1.36, 1.35, 1.34, 1.16]\n",
      "cancer cancers phyto carcinogenesis chemopreventive plant chemoprevention cancerous plants planting prevention malignant malignancy carcinogen tumorigenesis carcinogenic tumor adenocarcinoma oncogenesis carcinoma\n",
      "1 MED-3550 54.95491409301758 not-eval\n",
      "[5.2, 3.49, 2.37, 2.28, 2.27, 2.23, 2.1, 1.97, 1.94, 1.9, 1.89, 1.8, 1.55, 1.54, 1.52, 1.27, 1.21, 1.21, 1.2, 1.19]\n",
      "cancer cancers carcinogenesis chemopreventive angiogenesis tumor chemoprevention prevention antiangiogenic vegf cancerous angiogenic malignancy malignant oncology oncological tumorigenesis adenocarcinoma tumors carcinoma\n",
      "2 MED-3726 52.26643371582031 not-eval\n",
      "[5.28, 3.47, 2.77, 2.63, 2.56, 2.07, 1.97, 1.93, 1.47, 1.44, 1.36, 1.35, 1.28, 1.28, 1.26, 1.17, 1.13, 0.99, 0.97, 0.96]\n",
      "cancer cancers chemopreventive carcinogenesis chemoprevention cancerous vegetables prevention malignant tumor malignancy oncology tumorigenesis vegetable carcinoma anticancer adenocarcinoma strategy carcinogenic oncogenesis\n",
      "3 MED-3551 50.53462219238281 not-eval\n",
      "[5.06, 3.23, 3.15, 2.36, 2.29, 2.05, 1.93, 1.87, 1.86, 1.85, 1.78, 1.76, 1.62, 1.5, 1.45, 1.4, 1.28, 1.25, 1.21, 1.18]\n",
      "cancer cancers phyto plant angiogenesis carcinogenesis angiogenic cancerous chemopreventive vegf planting plants chemoprevention prevention tumor malignant carcinoma antiangiogenic adenocarcinoma vascular\n",
      "4 MED-4196 49.95339584350586 not-eval\n",
      "[5.05, 3.4, 3.3, 2.81, 2.58, 2.08, 2.0, 1.83, 1.82, 1.61, 1.5, 1.49, 1.4, 1.36, 1.29, 1.22, 1.22, 1.17, 0.99, 0.87]\n",
      "cancer carcinogenesis cancers chemopreventive chemoprevention phyto cancerous plant prevention tumorigenesis tumor oncogenesis malignant malignancy carcinoma carcinogenic carcinogen adenocarcinoma plants anticancer\n",
      "5 MED-4030 48.67909622192383 not-eval\n",
      "[5.16, 3.37, 2.68, 2.63, 2.33, 2.15, 2.04, 2.03, 1.98, 1.96, 1.68, 1.48, 1.46, 1.43, 1.28, 1.25, 1.19, 1.15, 1.12, 1.04]\n",
      "cancer cancers vegetables carcinogenesis vegetable chemopreventive chemoprevention prevention plant cancerous malignant carcinoma malignancy oncology adenocarcinoma oncological planting fv plants tumor\n",
      "6 MED-2435 48.59457778930664 not-eval\n",
      "[5.14, 3.49, 2.71, 2.64, 2.46, 2.29, 2.09, 2.09, 1.82, 1.43, 1.42, 1.4, 1.36, 1.34, 1.2, 1.2, 1.17, 1.07, 0.95, 0.92]\n",
      "cancer cancers carcinogenesis chemopreventive chemoprevention phyto plant cancerous prevention plants malignant carcinoma tumor planting adenocarcinoma malignancy anticancer tumorigenesis carcinogen oncogenesis\n",
      "7 MED-1146 46.91360855102539 not-eval\n",
      "[5.31, 3.52, 3.01, 2.89, 2.22, 2.18, 1.89, 1.89, 1.57, 1.54, 1.47, 1.43, 1.28, 1.26, 1.2, 1.17, 1.04, 1.01, 0.92, 0.9]\n",
      "cancer cancers vegetables vegetable carcinogenesis planting prevention cancerous fv chemoprevention chemopreventive malignant malignancy plant oncology oncological adenocarcinoma risk carcinogenic tumor\n",
      "8 MED-2439 46.91001892089844 not-eval\n",
      "[5.02, 3.32, 3.14, 2.4, 2.2, 2.16, 2.07, 1.98, 1.5, 1.41, 1.4, 1.38, 1.19, 1.12, 1.1, 0.99, 0.97, 0.87, 0.83, 0.8]\n",
      "cancer cancers plant plants carcinogenesis cancerous phyto planting malignant tumor chemopreventive malignancy carcinoma adenocarcinoma anticancer tumorigenesis vegetation oncology chemoprevention vegetable\n",
      "9 MED-2067 46.45176315307617 not-eval\n",
      "[4.99, 3.15, 2.44, 2.24, 2.06, 1.95, 1.8, 1.69, 1.6, 1.52, 1.45, 1.4, 1.3, 1.29, 1.16, 1.07, 1.06, 1.05, 1.04, 1.0]\n",
      "cancer cancers carcinogenesis chemopreventive cancerous tumor vegetables plant chemoprevention tumorigenesis prevention plants malignant carcinogen carcinoma malignancy adenocarcinoma oncogenesis nsc anticancer\n",
      "-------------\n",
      "dapt-splade-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt-splade/GenQ-dapt-splade-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4095 6.3792572021484375 not-eval\n",
      "[6.37]\n",
      "cancer\n",
      "1 MED-1564 6.053951740264893 1\n",
      "[5.89]\n",
      "cancer\n",
      "2 MED-2814 5.992645263671875 not-eval\n",
      "[6.08]\n",
      "cancer\n",
      "3 MED-3717 5.977495193481445 not-eval\n",
      "[5.97]\n",
      "cancer\n",
      "4 MED-4227 5.9157209396362305 not-eval\n",
      "[5.91]\n",
      "cancer\n",
      "5 MED-4070 5.903906345367432 not-eval\n",
      "[6.02]\n",
      "cancer\n",
      "6 MED-1531 5.717670917510986 1\n",
      "[5.99]\n",
      "cancer\n",
      "7 MED-1567 5.696262836456299 1\n",
      "[5.76]\n",
      "cancer\n",
      "8 MED-1717 5.66422176361084 not-eval\n",
      "[5.69]\n",
      "cancer\n",
      "9 MED-4096 5.6317315101623535 not-eval\n",
      "[5.74]\n",
      "cancer\n",
      "-------------\n",
      "dapt-59372\n",
      "path /home/gaia_data/iida.h/BEIR/datasets/nfcorpus/new_model/dapt/GenQ-dapt-splade-59372/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-3554 13.68480110168457 not-eval\n",
      "[6.74, 2.14, 1.99, 0.88, 0.65, 0.26]\n",
      "cancer ve carcinogenesis eosinophil malignancy anti\n",
      "1 MED-2357 12.826347351074219 not-eval\n",
      "[5.57, 2.95, 1.74, 1.68, 0.64, 0.37]\n",
      "cancergg eosinophil carcinogenesis anti malignancy\n",
      "2 MED-5326 11.714365005493164 not-eval\n",
      "[7.11, 3.78, 0.73]\n",
      "cancer carcinogenesis malignancy\n",
      "3 MED-4030 11.640615463256836 not-eval\n",
      "[7.58, 3.19, 0.77]\n",
      "cancer carcinogenesis malignancy\n",
      "4 MED-2247 11.636894226074219 not-eval\n",
      "[6.76, 3.64, 0.86, 0.29]\n",
      "cancer carcinogenesis malignancy anti\n",
      "5 MED-3550 11.622136116027832 not-eval\n",
      "[7.12, 3.0, 0.71, 0.67, 0.12]\n",
      "cancer carcinogenesis malignancy anti perfringens\n",
      "6 MED-4487 11.612100601196289 not-eval\n",
      "[7.42, 3.43, 0.86, 0.11]\n",
      "cancer carcinogenesis malignancy histories\n",
      "7 MED-3703 11.597021102905273 not-eval\n",
      "[7.08, 2.61, 1.33, 0.82]\n",
      "cancer carcinogenesis eosinophil malignancy\n",
      "8 MED-4070 11.524694442749023 not-eval\n",
      "[7.41, 3.22, 0.8, 0.13, 0.11]\n",
      "cancer carcinogenesis malignancy dysplasia histories\n",
      "9 MED-4117 11.331308364868164 not-eval\n",
      "[6.84, 2.44, 1.76, 0.48]\n",
      "cancer carcinogenesis eosinophil malignancy\n",
      "-------------\n",
      "splade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MED-4714 17.756385803222656 not-eval\n",
      "[5.51, 3.29, 2.72, 2.03, 1.13, 1.03, 0.91, 0.89, 0.17]\n",
      "cancer tumor food vegetables vegetable vs eat foods david\n",
      "1 MED-1146 17.479660034179688 not-eval\n",
      "[6.29, 3.64, 2.23, 1.65, 0.96, 0.92, 0.91, 0.64, 0.63, 0.19]\n",
      "cancer tumor food vegetables vegetable eat difference david foods dana\n",
      "2 MED-2075 17.17150115966797 not-eval\n",
      "[5.66, 3.28, 2.44, 1.63, 1.11, 0.91, 0.85, 0.34, 0.1]\n",
      "cancer tumor food vegetables foods vegetable eat david are\n",
      "3 MED-890 17.123666763305664 not-eval\n",
      "[5.92, 3.65, 2.6, 1.39, 1.27, 1.12, 0.65, 0.42]\n",
      "cancer tumor food vegetables foods eat vegetable david\n",
      "4 MED-3245 16.95833969116211 not-eval\n",
      "[5.39, 2.96, 2.88, 1.79, 1.46, 1.07, 0.92]\n",
      "cancer tumor food vegetables foods vegetable eat\n",
      "5 MED-4861 16.85017204284668 not-eval\n",
      "[5.81, 3.36, 2.24, 1.73, 1.02, 0.74, 0.62, 0.6]\n",
      "cancer tumor food vegetables vegetable eat foods david\n",
      "6 MED-4030 16.76387596130371 not-eval\n",
      "[6.13, 3.45, 2.34, 1.31, 1.3, 1.01, 0.59, 0.46]\n",
      "cancer tumor food foods vegetables eat vegetable david\n",
      "7 MED-5111 16.763378143310547 not-eval\n",
      "[5.46, 3.05, 2.65, 1.64, 1.26, 0.92, 0.91, 0.78, 0.16]\n",
      "cancer tumor food vs vegetables eat foods vegetable david\n",
      "8 MED-4024 16.734966278076172 not-eval\n",
      "[5.95, 3.56, 2.37, 1.6, 1.25, 0.95, 0.87, 0.14]\n",
      "cancer tumor food vegetables foods eat vegetable david\n",
      "9 MED-5066 16.658641815185547 not-eval\n",
      "[5.87, 3.32, 2.48, 1.52, 0.99, 0.92, 0.87, 0.59]\n",
      "cancer tumor food vegetables foods vegetable eat vs\n"
     ]
    }
   ],
   "source": [
    "observe_model = [\"adalm\", \"dapt-splade-59372\", \"dapt-59372\", \"splade\"]\n",
    "for qid in qids_dapt_59372_improve:\n",
    "    print(\"----------------------------\")\n",
    "    print(queries[qid])\n",
    "    for model_name in observe_model:\n",
    "        print(\"-------------\")\n",
    "        print(model_name)\n",
    "        analysis(model_name, qid, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c07919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
